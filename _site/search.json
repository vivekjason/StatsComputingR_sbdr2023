[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistical Computing in R 2023",
    "section": "",
    "text": "Welcome to the Statistical Computing in R! for Beginners to Intermediates organised by the Sector for Biostatistics and Data Repository, National Institutes of Health, Malaysia\n\n\n\n\n\n\n\nThis workshop lays the groundwork for addressing key practical aspects of programming and other essential computer skills needed for both research and implementation of statistical methods. The course offers an introduction to programming in R and the tidyverse, guidance on coding best practices, a primer on data visualization and data wrangling, as well as an exploration of both descriptive and inferential statistics using R. Additionally, the workshop also introduces the concept of regression analysis in R.\n\n\n\nHave a look at the schedule below and download the necessary .qmd files for each session. While I have included solutions- it would be way more beneficial to attempt these yourself first. Lets try to maximise learning in the next two days.\nIf you are new to R, don’t worry - start of with this deck to learn how to install the software and familiarise yourself with the environment.\n\n\n\n\n\n\nDate\nTime\nTopic\n\n\n\n\n10.7.2022 (Monday)\n08.30 am - 09.00 am\nRegistration\n\n\n\n9.00 am - 10.00 am\nIntroduction to R Software\n\n\n\n10.00 am - 12.30 pm\nData wrangling | Tutorial | Solutions\n\n\n\n12.30 pm - 02.00 pm\nBreak\n\n\n\n02.00 pm - 04.30 pm\nData Visualization | Tutorial | Solutions\n\n\n11.7.2022 (Tuesday)\n08.00 am – 08.30 am\nRegistration\n\n\n\n08.30 am - 11.30 am\nHypothesis testing | Tutorial | Solutions\n\n\n\n1.00 pm - 02.15 pm\nBreak\n\n\n\n02.15 pm - 04.30 pm\nIntroduction to Regression | Tutorial | Solutions\n\n\n\n04.30 pm - 05.00 pm\nQ&A\n\n\n\n\n\n\n\n\n\n\n\nVivek Jason\nJason is a gazetting Public Health Physician passionate about epidemiology, infectious diseases and data science. He spends his time between coding, parenting a toddler and pondering the fate of the universe.\n\n\n\n\n\nAng Swee Hung\nSwee Hung is a training Public Health Physician from the Institute for Clinical research that works heavily in the fields of non-communicable disease epidemiology. Renowned for her calmness under pressure- Swee Hung also enjoys the serenity of long drives and the excitement of travelling. Her next destination is Shanghai.\n\n\n\n\n\nEvi Diana\nEvi is a statistician with vast expertise in complex sample analysis and clustering. The only person whose math you should trust in this workshop- Evi always has a smile on her face.\n\n\n\nThis course was developed and is maintained by Vivek Jason.\nThe following individuals have contributed to improving the course or materials have been adapted from their courses: R for Applied Epidemiology and Public Health, Stephanie Hicks, Roger D. Peng, Naim Rashid.\nThe course materials are licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. Linked and embedded materials are governed by their own licenses. I assume that all external materials used or embedded here are covered under the educational fair use policy. If this is not the case and any material displayed here violates copyright, please let me know and I will remove it."
  },
  {
    "objectID": "solutions/regression_solutions.html",
    "href": "solutions/regression_solutions.html",
    "title": "Practical Statistics 4: Regression",
    "section": "",
    "text": "Task 1: Univariate Linear Regression\nQuestion: Perform a univariate linear regression to predict “age” using the “male” variable.\nSteps:\n\nInstall and load the required packages: tidyverse and broom.\nFilter the dataset to remove missing values in the “age” and “male” columns.\nFit a univariate linear regression model using the lm() function.\nSummarise the model using tidy() from the broom package.\n\nSolution:\n\n# Step 1\n#install.packages(c(\"tidyverse\", \"broom\"))\nlibrary(tidyverse)\nlibrary(broom)\n\n# Step 2\nc19_df <- c19_df %>% filter(!is.na(age), !is.na(male))\n\n# Step 3\nmodel <- lm(age ~ male, data = c19_df)\n\n# Step 4\ntidy(model)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)    63.6      0.132    482.   0       \n2 male           -1.59     0.174     -9.14 6.51e-20\n\n\n\n\nTask 2: Multivariate Linear Regression\nQuestion: Perform a multivariate linear regression to predict “age” using the “male” and “malaysian” variables.\nSteps:\n\nFilter the dataset to remove missing values in the relevant columns.\nFit a multivariate linear regression model using the lm() function.\nSummarise the model using gtsummary().\nSave the output as a document\n\nSolution:\n\n# Step 1\nc19_df <- c19_df %>% filter(!is.na(age), !is.na(male), !is.na(malaysian))\n\n# Step 2\nmodel <- lm(age ~ male + malaysian, data = c19_df)\n\n# Step 3\nmodel %>% \n  tbl_regression() %>%\n  as_flex_table() %>%\n  flextable::save_as_docx(path = \"regression.docx\")\n\n\n\nTask 3: Univariate Logistic Regression\nQuestion: Perform a univariate logistic regression to predict “male” (binarize to 0 and 1) using the “age” variable.\nSteps:\n\nFilter the dataset to remove missing values in the relevant columns.\nFit a univariate logistic regression model using the glm() function, specifying the family as “binomial”.\nSummarise the model using tidy().\n\nSolution:\n\n# Step 1\nc19_df <- c19_df %>% filter(!is.na(age), !is.na(male))\n\n# Step 2\nmodel <- glm(male ~ age, data = c19_df, family = \"binomial\")\n\n# Step 3\ntidy(model)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)  0.667    0.0414       16.1  1.74e-58\n2 age         -0.00581  0.000637     -9.12 7.45e-20\n\n\n\n\nTask 4: Multivariate Logistic Regression\nQuestion: Perform a multivariate logistic regression to predict “male” using the “age” and “malaysian” variables.\nSteps:\n\nFilter the dataset to remove missing values in the relevant columns.\nFit a multivariate logistic regression model using the glm() function, specifying the family as “binomial”.\nSummarise the model using gtsummary().\nSave the output as a document\n\nSolution:\n\n# Step 1\nc19_df <- c19_df %>% filter(!is.na(age), !is.na(male), !is.na(malaysian))\n\n# Step 2\nmodel <- glm(male ~ age + malaysian, data = c19_df, family = \"binomial\")\n\n# Step 3\nmodel %>%\n  tbl_regression(exponentiate = TRUE) %>%\n  as_flex_table() %>%\n  flextable::save_as_docx(path = \"regression.docx\")\n\n\n\nTask 5: Model Evaluation\nQuestion: Evaluate the logistic regression model from Task 4 using AUC-ROC.\nSteps:\n\nInstall and load the pROC package (Note: Upon up the documentation to figure out the nuts and bolts.)\nUse the predict() function to get the predicted probabilities from the logistic regression model.\nUse the roc() function to compute the AUC-ROC.\n\nSolution:\n\n# Step 1\n#install.packages(\"pROC\")\nlibrary(pROC)\n\nType 'citation(\"pROC\")' for a citation.\n\n\n\nAttaching package: 'pROC'\n\n\nThe following objects are masked from 'package:stats':\n\n    cov, smooth, var\n\n# Step 2\nprobabilities <- predict(model, type = \"response\")\n\n# Step 3\nroc_obj <- roc(c19_df$male, probabilities)\n\nSetting levels: control = 0, case = 1\n\n\nSetting direction: controls < cases\n\n# Display AUC\nauc(roc_obj)\n\nArea under the curve: 0.5288"
  },
  {
    "objectID": "tutorials/data_viz_tutorial.html",
    "href": "tutorials/data_viz_tutorial.html",
    "title": "Practical session 2: R-tistic Insights- Visualising your data in R",
    "section": "",
    "text": "Call the data in\nCreate a new variable vaccinated that indicates if an individual is fully vaccinated (dose2) or not. (Tip: use mutate and ifelse)\nPlot a scatterplot showing the relationship between age and date. Use the new variable vaccinated variable to color the points using the colour hex #1369FF and #00B556. (Tip: Use the command scale_colour_manual)\nNext try using the date_dose3 instead of date. Anything interesting?\n\n\n\n\n\nCreate a line chart to represent the cumulative number of vaccinations by dose over time.\nSelect all the date_doseX, and state\nPivot the data into long form (Tip: use the pivot_long function) and count the number of dose given on each date\nComplete the series of dates using complete\nPlot the the different doses by date across time and facet by state\nColour date_dose3= #A3D2D5. Maintain the other 2 colours.\nApply a pre-set theme\n\n\n\n\n\nCall data in\nReplace all empty cells with NA in column brand2\nGroup by state and brand2 and summarise the number of groups in each brand, state\nPlot a box plot on the distribution of deaths by brand2\nTitle should be “Number of Deaths by Vaccine Brand and Date” with x-axis labels of “Vaccine Brand” and y-axis labels of “Number of Deaths” (Tip: Use labs)\n\n\n\n\n\nCall in data\nSelect on state, malaysian, bid\nFactorise the variable\nBuild a grouped bar chart by state and bid status\nFacet wrap by malaysian\nTitle should be “Deaths by State, Brought-in-Dead Status, and Malaysian Status” with x-axis labels of “State” and y-axis labels of “Number of Deaths”. Legend label should be “Brought-in-Dead Status”.\nApply theme_minimal and adjust the x-axis text to be perpendicular (90 degrees) to the axis (Tip: Use theme (axis.text.x=element_text()))\nWhat should you change to transform this into a stacked bar chart?\n\n\n\n\n\nEasy peasy lemon squesy- just save all of the above 4 plots. (Tip: use ggsave())\nHow can we change output format, quality, size"
  },
  {
    "objectID": "tutorials/data_wranggling_tutorial.html",
    "href": "tutorials/data_wranggling_tutorial.html",
    "title": "Practical session 1: Untangling Data with Tidyverse: Data wranggling in R",
    "section": "",
    "text": "Task 1: Calculate the average age for deaths by state and find the state with the highest average age.\nSteps:\n\nFirst, we need to group the data by state.\nThen, we can summarize the average age per state using summarise.\nUse arrange to sort the average age in descending order to find the state with the highest average age.\n\n\n\nTask 2: Determine the proportion of male to female deaths in each state.\nSteps:\n\nUsing mutate, create a new column called gender using ifelse to convert the male column to ‘Male’ and ‘Female’.\nGroup the data by state and gender.\nSummarise the count of each gender in each state.\nCreate a new column with the proportion of each gender in each state.\n\n\n\nTask 3: Determine the total number of deaths by month and year.\nSteps:\n\nConvert the date column to Date type if it’s not already.\nUse mutate to create new columns year and month using the year and month functions from the lubridate package.\nGroup the data by year and month.\nUse summarise to count the number of deaths.\n\n\n\nTask 4: Determine if comorbidities are more common in Malaysian or non-Malaysian deaths.\nSteps:\n\nCreate a new column nationality that categorizes malaysian into ‘Malaysian’ and ‘Non-Malaysian’ using mutate and ifelse.\nGroup by nationality.\nSummarise the average comorbidity rate (comorb).\n\n\n\nTask 5: Find out the most common vaccine brand combination that was administered.\nSteps:\n\nUse mutate to create a new column brands_combo that concatenates brand1, brand2, and brand3.\nfilter to keep only those rows where brands_combo is not empty.\nGroup by brands_combo.\nCount the number of occurrences for each vaccine brand combination using summarise."
  },
  {
    "objectID": "tutorials/inferential_stats_tutorial.html",
    "href": "tutorials/inferential_stats_tutorial.html",
    "title": "Practical Statistics 3: Descriptive and Inferential Statistics",
    "section": "",
    "text": "Task 2: Descriptive statistics using gtsummary\nQuestion: Create a descriptive statistics table for age, male, bid, and malaysian variables using gtsummary.\nSteps:\n\nInstall and load the gtsummary package.\nCreate a subset of the data with the selected variables (Note: Select any five variables).\nUse the tbl_summary() function to compute and display the descriptive statistics.\nStratify by any other selected variable.\n\n\n\nTask 3: Inferential statistics using rstatix\nQuestion: Test if there is a significant difference in age between males and females using the t-test.\nSteps:\n\nInstall and load the rstatix package.\nFilter the dataset to remove missing values in the “age” and “male” columns.\nRecode the “male” variable to factor.\nConduct a t-test to compare the means.\n\n\n\nTask 4: Inferential statistics using gtsummary\nQuestion: Test if there is a significant difference in age between Malaysians and non-Malaysians using the t-test, and present the results in a table using gtsummary.\nSteps:\n\nRecode the “malaysian” variable to factor (Tip: Use the factor function).\nUse the tbl_summary() function to present the results.\n\nSolution:\n\n\nTask 5: Correlations using corrr\nQuestion: Compute the correlation between age, male, bid, and malaysian variables, and represent it in a correlation plot (Note: The selection of categorical variables is by design- just to practice the selection and presentation)\nSteps:\n\nInstall and load the corrr package.\nCreate a subset of the data with the selected variables.\nCompute the correlation matrix (Note: Try ?network_plot and see how this can be used)\n\n\n\n\n\n\nThis would be the outcome if anything was highly correlated in our data."
  },
  {
    "objectID": "tutorials/regression_tutorial.html",
    "href": "tutorials/regression_tutorial.html",
    "title": "Practical Statistics 4: Regression",
    "section": "",
    "text": "Task 2: Multivariate Linear Regression\nQuestion: Perform a multivariate linear regression to predict “age” using the “male” and “malaysian” variables.\nSteps:\n\nFilter the dataset to remove missing values in the relevant columns.\nFit a multivariate linear regression model using the lm() function.\nSummarise the model using gtsummary().\nSave the output as a document\n\n\n\nTask 3: Univariate Logistic Regression\nQuestion: Perform a univariate logistic regression to predict “male” (binarize to 0 and 1) using the “age” variable.\nSteps:\n\nFilter the dataset to remove missing values in the relevant columns.\nFit a univariate logistic regression model using the glm() function, specifying the family as “binomial”.\nSummarise the model using tidy().\n\n\n\nTask 4: Multivariate Logistic Regression\nQuestion: Perform a multivariate logistic regression to predict “male” using the “age” and “malaysian” variables.\nSteps:\n\nFilter the dataset to remove missing values in the relevant columns.\nFit a multivariate logistic regression model using the glm() function, specifying the family as “binomial”.\nSummarise the model using gtsummary().\nSave the output as a document\n\n\n\nTask 5: Model Evaluation\nQuestion: Evaluate the logistic regression model from Task 4 using AUC-ROC.\nSteps:\n\nInstall and load the pROC package (Note: Upon up the documentation to figure out the nuts and bolts.)\nUse the predict() function to get the predicted probabilities from the logistic regression model.\nUse the roc() function to compute the AUC-ROC."
  },
  {
    "objectID": "lectures/introduction_R.html",
    "href": "lectures/introduction_R.html",
    "title": "Introduction to R",
    "section": "",
    "text": "Welcome to Statistical Computing in R! (Beginner-Intermediate) organised by the Sector for Biostatistics and Data Respository, National Instititues of Health."
  },
  {
    "objectID": "lectures/introduction_R.html#speakers",
    "href": "lectures/introduction_R.html#speakers",
    "title": "Introduction to R",
    "section": "Speakers",
    "text": "Speakers\n\n\n\n\n\nVivek Jason\nJason is a gazetting Public Health Physician passionate about epidemiology, infectious diseases and data science. He spends his time between coding, playing with his toddler and pondering the fate of the universe.\n\n\n\n\n\nAng Swee Hung\nSwee Hung is a training Public Health Physician that works heavily in the fields of non-communicable disease epidemiology. Renowned for her calmness under pressure- Swee Hung also enjoys the serenity of long drives.\n\n\n\n\n\nEvi Diana\nEvi is a statistician with vast expertise in complex sample analysis and clustering. The only person whose math you should trust in this workshop- Evi always has a smile on her face.\n\nSchedule\n\n\n\n\n\n\n\n\nDate\nTime\nTopic\n\n\n\n\n10.7.2022 (Monday)\n08.30 am - 09.00 am\nRegistration\n\n\n\n9.00 am - 10.00 am\nIntroduction to R Software\n\n\n\n10.00 am - 12.30 pm\nData wrangling\n\n\n\n12.30 pm - 02.00 pm\nBreak\n\n\n\n02.00 pm - 04.30 pm\nData Visualization\n\n\n11.7.2022 (Tuesday)\n08.00 am – 08.30 am\nRegistration\n\n\n\n08.30 am - 11.30 am\nHypothesis testing\n\n\n\n1.00 pm - 02.15 pm\nBreak\n\n\n\n02.15 pm - 04.30 pm\nIntroduction to Regression\n\n\n\n04.30 pm - 05.00 pm\nQ&A\n\n\n\n\n\nWhat will we learn in the next hour?\n\nSome backround on R\nUnderstanding R and RStudio\nGrammar of R\nTaking the next step\n\n\n\nWhat is…\n\n\n\n\n\n\n\na software package for statistical computing and graphics\na collection of 18,636packages (as of September 2020)!\na (not ideal) programming language\na work environment, widely used, POWERFUL!\n\n\n\nWhy use R\n\nIt’s free!\nIt runs on a variety of platforms including Windows, Unix and MacOS.\nIt provides an unparalleled platform for programming new statistical methods in an easy and straightforward manner.\nIt contains advanced statistical routines not yet available in other packages.\nIt has state-of-the-art graphics capabilities\nThe next step for open-science initiatives chief being reproducibility\n\n\n\n\n\n\n\nA note on reproducibility\n\n\n\n\nReplication, whereby scientific questions are examined and verified independently by different scientists, is the gold standard for scientific validity.\nReplication can be difficult and often there are no resources to independently replicate a study.\nReproducibility, whereby data and code are re-analyzed by independent scientists to obtain the same results of the original investigator, is a reasonable minimum standard when replication is not possible.\n\n\n\n\n\nReproducibility and Literate Programming\nOne basic idea to make writing reproducible reports easier is what’s known as literate statistical programming (or sometimes called literate statistical practice). This comes from the idea of literate programming in the area of writing computer programs.\nThe idea is to think of a report or a publication as a stream of text and code.\n\nThe text is readable by people and the code is readable by computers.\nThe analysis is described in a series of text and code chunks.\nEach kind of code chunk will do something like load some data or compute some results.\nEach text chunk will relay something in a human readable language.\n\nThere might also be presentation code that formats tables and figures and there’s article text that explains what’s going on around all this code. This stream of text and code is a literate statistical program or a literate statistical analysis.\n\n\nCRAN:Comprehensive R Archive Network\nAt a higher level one “limitation” of R is that its functionality is based on consumer demand and (voluntary) user contributions. If no one feels like implementing your favorite method, then it’s your job to implement it (or you need to pay someone to do it). The capabilities of the R system generally reflect the interests of the R user community. As the community has ballooned in size over the past 10 years, the capabilities have similarly increased. This can be seen in the exponential increase in packages on CRAN\n\n\n\n\n\n\n\nHistory time\n\nS was developed at Bell Labs, starting in the 1970s\nR was created in the 1990s by Ross Ihaka and Robert Gentleman\nR was based on S, with code written in C\nS largely was used to make good graphs – not an easy thing in 1975. R, like S, is quite good for graphing\n\n\n\n\nDesign of the R System\nThe primary R system is available from the Comprehensive R Archive Network, also known as CRAN. CRAN also hosts many add-on packages that can be used to extend the functionality of R.\nThe R system is divided into 2 conceptual parts:\n\nThe “base” R system that you download from CRAN:\n\n\nLinux\nWindows\nMac\n\n\nEverything else.\n\nR functionality is divided into a number of packages.\n\nThe “base” R system contains, among other things, the base package which is required to run R and contains the most fundamental functions.\nThe other packages contained in the “base” system include utils, stats, datasets, graphics, grDevices, grid, methods, tools, parallel, compiler, splines, tcltk, stats4.\nThere are also “Recommended” packages: boot, class, cluster, codetools, foreign, KernSmooth, lattice, mgcv, nlme, rpart, survival, MASS, spatial, nnet, Matrix.\n\nWhen you download a fresh installation of R from CRAN, you get all of the above, which represents a substantial amount of functionality. However, there are many other packages available:\n\nThere are over 10,000 packages on CRAN that have been developed by users and programmers around the world.\nThere are also many packages associated with the Bioconductor project.\nPeople often make packages available on their personal websites; there is no reliable way to keep track of how many packages are available in this fashion.\n\n\n\nAt its core R is a programming language\n\nConcepts such as loops and functions speed up and simplify analytic processes\nIf you want R to be (relatively) fast, take advantage of vector operations; e.g., use the replicate command (rather than a loop) or the apply function.\noptimising computation is critical to newer processes i.e. big data\n\n\n\nR is object oriented\n\ne.g., MyModel <- lm(wt ~ ht, data = mydata)\nthen hist(MyModel$residuals)\nNote that lm(wt ~ ht*age + log(bp), data = mydata) regresses wt on ht, age, the ht-by-age interaction, and log(bp)\nThere is no need to create the interaction or the log(bp) variable outside of the lm() command\nanother e.g.\nmod1 <- lm(wt ~ ht*age + log(bp), data = mydata)\nmod2 <- lm(wt ~ ht + log(bp), data = mydata)\nanova(mod2, mod1) gives a nested/ interaction F-test\n\n\n\nLimitations\n\nfresh non-coders may find it difficult at first , the curve is steep especially if you have no background\nhundreds of packages mean learning 100s of different things and styles - analysis is much more transient\nSPSS, STATA use a much more ordered approach - fresh non-coders may find it difficult at first\ngenerally a intepreted language (vs compiled), this makes certain operations clunky and slow like looping\n\n\nNonetheless The R paradigm is different- its uses a more iterative approach and as such analysis is more flexible, makes a more in depth inquiry of data Mastery is key to tapping the potential of data science in real-world and research settings The first key to mastery of R is….\nUNINSTALL SPSS AS.. QUICKLY.. AS.. YOU.. CAN!!\n\n\n\n\n\n\n\nRstudio\n\nAn Integrated Development Environment (IDE) for R\nA gift, from J.J. Allaire (Macalester College, ’91) to the world\nAn easy (easier) way to use R\nAvailable as a desktop product or, run off a server or cloud\nRecently renamed as Posit- to include Python, VS and Quatro\nFree to a degree!\n\n\n\n\n\n\n\n\n\nRStudio environment\n\n\n\n\n\n\n\nSetting a working directory\nCheck you working directory by\n\n\n\nYou can then set your working directory like this\n\n\n\n\n\n\n\n\n\nSetting a work directory like this is called an absolute path and in statistical computing is a frowned upon practice as it locks directories to you system only. Instead we should utilise relative paths.\n\n\n\n\n\n\nA relative path should look like this\n\n\n\nThere are even better practices for sustainability and reproducibility such but we wont cover those practices here. You can find more information in this post\n\n\nReading data into R\nThis section demonstrates the fundamental functions required to read and write data in R.\nIn base R, there are key functions for reading data:\n\nread.table() & read.csv(): used for reading tabular data\nreadLines(): used for reading lines from a text file\n\nCorresponding functions exist for writing data:\n\nwrite.table(): used to write tabular data to text files or connections, such as CSV\nwriteLines(): used to write character data line-by-line to a file or connection\n\nLet’s attempt to read data into R using the read.csv() function.\n\ndf <- read.csv(\"data/yourfilename.csv\")#this is just an example\n\nYou can even pull a csv straight from the web\n\ndf <- read.csv(\"https://raw.githubusercontent.com/MoH-Malaysia/data-darah-public/main/newdonors_state.csv\")\n\nYou can export he above csv to you computer by\n\n\n\nTo extract a specific column, we can use the $ symbol:\n\ndf$hospital\n\nNULL\n\n\nAlmost all imaginable formats can be imported/ exported into R. For a more in depth explanation you can have a look at this book chapter.\n\n\nBase R Grammar\n\nResults of calculations can be stored in objects using the assignment operators: An arrow (<-) formed by a smaller than character and a hyphen without a space! The equal character (=).\nObject names cannot contain `strange’ symbols like !, +, -, #.\nA dot (.) and an underscore ( ) are allowed, also a name starting with a dot.\nObject names can contain a number but cannot start with a number.\nR is case sensitive, X and x are two different objects, as well as temp and temP.\n\n\nLets do some coding\nSimple calculations\n\n5\n\n[1] 5\n\n\n\n2+5\n\n[1] 7\n\n\n\nlog(5)\n\n[1] 1.609438\n\n\n\n\nStoring objects\nStore a number\n\nx <- 2\nx\n\n[1] 2\n\n\nTry it with =\n\nx=2\nx\n\n[1] 2\n\n\nSame results\nStore an object\n\nx <- \"Hello\"\nx\n\n[1] \"Hello\"\n\n\nStore a string of numbers\n\nx <- c(1:10)\nx\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\nCheck the string and subset some values based on criteria\n\nx>8\n\n [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE\n\n\n\nx < 5\n\n [1]  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE\n\n\n\nx[(x>8) | (x<5)]\n\n[1]  1  2  3  4  9 10\n\n\n\n\nVectors\nWrite a vector of weights\n\nweight <- c(55, 67, 99, 87, 62, 45, 32, 6, 22, 88)\n\nSubset the third value\n\nweight[3]\n\n[1] 99\n\n\nSubset the 4th to 6th value\n\nweight[4:6]\n\n[1] 87 62 45\n\n\nDefine another vector of weights\n\nheight <- c(123, 165, 187, 201, 152, 157, 134, 23, 91, 197)\n\nEstimate a BMI\n\nbmi <- weight/((height/100)^2)\nbmi\n\n [1]  36.35402  24.60973  28.31079  21.53412  26.83518  18.25632  17.82134\n [8] 113.42155  26.56684  22.67515\n\n\n\n\nDescriptive of the vector\n\nlength(height)\n\n[1] 10\n\n\n\nmean (weight)\n\n[1] 56.3\n\n\n\nvar(height)\n\n[1] 2951.333\n\n\n\n\nMatrices\nDefine a new vector\n\nobs <- 1:10\n\nJoin them into a matrix\n\nm <- cbind(obs, height, weight, bmi)\n\nDescribe the matrix\n\ntypeof(m)\n\n[1] \"double\"\n\n\n\nclass(m)\n\n[1] \"matrix\" \"array\" \n\n\n\nis.matrix(m)\n\n[1] TRUE\n\n\n\ndim(m)\n\n[1] 10  4\n\n\n\n\nQuick and dirty plots in base R\n\nxplot <- plot(height, weight, ylab=\"Weight\", xlab=\"Height\")\n\n\n\n\n\nxplot\n\nNULL\n\n\n\n\nDataframes\nConvert the earlier matrix into a df\n\ndf <- as.data.frame(m)\n\nCheck the column names\n\nnames(df)\n\n[1] \"obs\"    \"height\" \"weight\" \"bmi\"   \n\n\nSummarise the columns\n\nsummary(df)\n\n      obs            height          weight           bmi        \n Min.   : 1.00   Min.   : 23.0   Min.   : 6.00   Min.   : 17.82  \n 1st Qu.: 3.25   1st Qu.:125.8   1st Qu.:35.25   1st Qu.: 21.82  \n Median : 5.50   Median :154.5   Median :58.50   Median : 25.59  \n Mean   : 5.50   Mean   :143.0   Mean   :56.30   Mean   : 33.64  \n 3rd Qu.: 7.75   3rd Qu.:181.5   3rd Qu.:82.00   3rd Qu.: 27.94  \n Max.   :10.00   Max.   :201.0   Max.   :99.00   Max.   :113.42  \n\n\n\n\nSome other importannt grammar\n\nls() lists all the function objects in the environment\n\n\nls()\n\n\nrm() removes a particular function, rm(list=ls()) empties the environment\n\n\nrm(x)\n\n\n\n\nSpecial characters\n\nNA: Not Available (i.e. missing values)\nNaN: Not a Number (e.g. 0/0)\nInf: Infinity\n-Inf: Minus Infinity.\n\nFor instance 0 divided by 0 gives a NaN, but 1 divided by 0 gives Inf.\n\nThere are many ways to skin a cat in R\n\n\n\n\n\nFor instance\n\nmean(df$height) \n\n[1] 143\n\n\nOr\n\nwith(df, mean(height))\n\n[1] 143\n\n\nOr\n\nmean(height, data=df)\n\n[1] 143\n\n\nOr for a plot you could\n\nplot(df$height,df$weight)\n\n\n\n\nor\n\nwith(df, plot(height,weight)) \n\n\n\n\nor\n\nplot(weight~height, data=df)\n\n\n\n\nOf course not every thing will work\n\nplot(height, weight, data=df)\n\nWarning in plot.window(...): \"data\" is not a graphical parameter\n\n\nWarning in plot.xy(xy, type, ...): \"data\" is not a graphical parameter\n\n\nWarning in axis(side = side, at = at, labels = labels, ...): \"data\" is not a\ngraphical parameter\n\nWarning in axis(side = side, at = at, labels = labels, ...): \"data\" is not a\ngraphical parameter\n\n\nWarning in box(...): \"data\" is not a graphical parameter\n\n\nWarning in title(...): \"data\" is not a graphical parameter\n\n\n\n\n\n\n\n\nA word on the tidyverse\n\nThe tidyr and dplyr packages handle SQL-ytpe work: merging files, extracting subsets, etc.\n\n\n#install tidyerse\ninstall.packages(\"tidyverse\")\n\n#load dtidyverse\nlibrary(tidyverse)\n\n#wranggle data\nsub_df <- df %>% filter(bmi>20) %>% \n  mutate(BMI=bmi*bmi)#takes a sample of size 5000, extracts only the rows for which age > 18, and saves the result in newNCHS\n\nThe tidyverse framework is AMAZING and we will focus on utilising this framework for the remainder of this workshop.\n\n\n\n\n\n\nTip\n\n\n\n\nNobody remembers everything\nFirst thing to check is CRAN- look for documentation of package\ntype ? in console\nStackoverflow, Rstudio forum etc\nREMEMBER R IS ALL ABOUT COMMUNITY\n\n\n\n\n\nAcknowledgements\nMaterial for this lecture was borrowed and adopted from\n\nhttps://stephaniehicks.com/jhustatcomputing2022/\nhttps://rafalab.github.io/dsbook\nhttps://rmd4sci.njtierney.com\n\n\n\nAdditional Resources\n\n\n\n\n\n\nTip\n\n\n\n\nProgramming in R\n\n\nAn Introduction to R Complete introduction to base R\nR for Data Science Introduction to data analysis using R\nAdvanced R In-depth discussion of programming in R\n\n\nData viz in R\n\n\nData Visualization\nElegant Graphics for Data Analysis\n\n\nExtensions to R\n\n\nProgramming interactive R-apps using Shiny\nR markdown Integrate code and output into typeset documents and slide\nRStudio Cheat Sheets Cheatsheets for numerous packages."
  },
  {
    "objectID": "data_viz_solutions.html",
    "href": "data_viz_solutions.html",
    "title": "Practical session 2: R-tistic Insights- Visualising your data in R",
    "section": "",
    "text": "#load packages\nrequired_packages <- c(\"tidyverse\", \"rio\", \"here\", \"stringr\", \"lubridate\", \"ggforce\")\nnot_installed <- required_packages[!(required_packages %in% installed.packages()[ , \"Package\"])]    \nif(length(not_installed)) install.packages(not_installed)                                           \nsuppressWarnings(lapply(required_packages, require, character.only = TRUE))\n\nLoading required package: tidyverse\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\nLoading required package: rio\n\nLoading required package: here\n\nhere() starts at C:/R/nih_training/StatsComputingR_sbdr2023\n\nLoading required package: ggforce\n\n#call in data\nc19_df <- read.csv(\"https://raw.githubusercontent.com/MoH-Malaysia/covid19-public/main/epidemic/linelist/linelist_deaths.csv\")\n\n\n\n\nCall the data in\nCreate a new variable vaccinated that indicates if an individual is fully vaccinated (dose2) or not. (Tip: use mutate and ifelse)\nPlot a scatterplot showing the relationship between age and date. Use the new variable vaccinated variable to color the points using the colour hex #1369FF and #00B556. (Tip: Use the command scale_colour_manual)\nNext try using the date_dose3 instead of date. Anything interesting?\n\nSolution:\n\n#clean data\nc19_df <- c19_df %>% \n  mutate(across(where(is.character), na_if, \"\"),\n         vaccinated= ifelse(is.na(date_dose2), 0, 1))\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `across(where(is.character), na_if, \"\")`.\nCaused by warning:\n! The `...` argument of `across()` is deprecated as of dplyr 1.1.0.\nSupply arguments directly to `.fns` through an anonymous function instead.\n\n  # Previously\n  across(a:b, mean, na.rm = TRUE)\n\n  # Now\n  across(a:b, \\(x) mean(x, na.rm = TRUE))\n\nscatter_plot <- ggplot(data=c19_df) +\n  geom_point(mapping=aes(x=date, y=age, col=factor(vaccinated))) +\n  scale_colour_manual(name=\"Vaccination status\",\n                      values = c(`0`=\"#1369FF\", `1`=\"#00B556\"),\n                      labels = c(`0`=\"Unvaccinated\", `1`=\"Vaccinated\"))\nscatter_plot\n\n\n\n\n\n\n\n\nCreate a line chart to represent the cumulative number of vaccinations by dose over time.\nSelect all the date_doseX, and state\nPivot the data into long form (Tip: use the pivot_long function) and count the number of dose given on each date\nComplete the series of dates using complete\nPlot the the different doses by date across time and facet by state\nColour date_dose3= #A3D2D5. Maintain the other 2 colours.\nApply a pre-set theme\n\nSolution:\n\nvaccine_df <- c19_df %>% select(state, date_dose1, date_dose2, date_dose3) %>%\n  mutate(across(contains(\"date\"), ~as.Date(., format = \"%Y-%m-%d\"))) %>%\n  pivot_longer(cols = starts_with(\"date_dose\"), \n               names_to = \"dose\", \n               values_to = \"date\", \n               values_drop_na = TRUE) %>%\n  group_by(state, dose, date) %>%\n  summarise(count = n(), .groups = \"drop\") %>%\n  group_by(state, dose) %>% \n  complete(date = seq.Date(min(date, na.rm = TRUE), max(date, na.rm = TRUE), by = \"day\"), fill = list(count = 0))\n\n#plot\nline_plot <- ggplot(data=vaccine_df) +\n  geom_area(mapping=aes(x=date, y=count, fill=dose))+\n  scale_fill_manual(name=\"Vaccination status\",\n                      values = c(\"date_dose1\"=\"#1369FF\", \"date_dose2\"=\"#00B556\", \"date_dose3\"=\"#A3D2D5\"),\n                      labels = c(\"date_dose1\"=\"Dose 1\", \"date_dose2\"=\"Dose 2\", \"date_dose3\"=\"Dose 3\")) +\n  facet_wrap(~state, ncol = 4, scales=\"free_y\")+\n  theme_minimal()\nline_plot\n\n\n\n\n\n\n\n\nCall data in\nReplace all empty cells with NA in column brand2\nGroup by state and brand2 and summarise the number of groups in each brand, state\nPlot a box plot on the distribution of deaths by brand2\nTitle should be “Number of Deaths by Vaccine Brand and Date” with x-axis labels of “Vaccine Brand” and y-axis labels of “Number of Deaths” (Tip: Use labs)\n\nSolution:\n\nc19_df <- read.csv(\"https://raw.githubusercontent.com/MoH-Malaysia/covid19-public/main/epidemic/linelist/linelist_deaths.csv\")\n\nc19_df <- c19_df %>%\n  mutate(brand2 = replace_na(brand2, \"Unvax\")) %>%\n  filter(brand2 %in% c(\"AstraZeneca\", \"Pfizer\", \"Sinovac\", \"Unvax\")) %>%\n  group_by(state, brand2) %>%\n  summarise(deaths = n(), .groups = \"drop\")\n\nboxplot_plot <- ggplot(c19_df) +\n  geom_boxplot(aes(x = brand2, y = deaths, col=brand2)) +\n  labs(x = \"Vaccine Brand\", y = \"Number of Deaths\", \n       title = \"Number of Deaths by Vaccine Brand and Date\") +\n  theme_minimal()\nboxplot_plot\n\n\n\n\n\n\n\n\nCall in data\nSelect on state, malaysian, bid\nFactorise the variable\nBuild a grouped bar chart by state and bid status\nFacet wrap by malaysian\nTitle should be “Deaths by State, Brought-in-Dead Status, and Malaysian Status” with x-axis labels of “State” and y-axis labels of “Number of Deaths”. Legend label should be “Brought-in-Dead Status”.\nApply theme_minimal and adjust the x-axis text to be perpendicular (90 degrees) to the axis (Tip: Use theme (axis.text.x=element_text()))\nWhat should you change to transform this into a stacked bar chart?\n\nSolution:\n\nc19_df <- read.csv(\"https://raw.githubusercontent.com/MoH-Malaysia/covid19-public/main/epidemic/linelist/linelist_deaths.csv\")\n\nc19_df  <- c19_df %>%\n  mutate(malaysian = if_else(malaysian == 1, \"Malaysian\", \"Non-Malaysian\"),\n         bid = if_else(bid == 1, \"Brought-in-Dead\", \"Hospital Death\")) %>%\n  mutate(across(c(malaysian, bid), factor))  # Convert these columns to factors\n\n# Create the grouped bar chart\nbar_plot <- ggplot(c19_df, aes(x = state, fill = bid)) +\n  geom_bar(position = \"dodge\") +\n  facet_wrap(~malaysian) +\n  labs(x = \"State\", y = \"Number of Deaths\", \n       title = \"Deaths by State, Brought-in-Dead Status, and Malaysian Status\",\n       fill = \"Brought-in-Dead Status\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))  # Rotate x-axis labels for better visibility\nbar_plot\n\n\n\n#question 8 remove position=dodge \n\n\n\n\n\nEasy peasy lemon squesy- just save all of the above 4 plots. (Tip: use ggsave())\nHow can we change output format, quality, size\n\nSolution:\n\nggsave(\"scatter_plot.png\", scatter_plot)\nggsave(\"line_plot.pdf\", line_plot, dpi=300)\nggsave(\"boxplot_plot.svg\", boxplot_plot, unit=\"px\", height=1080, width = 1920)\nggsave(\"bar_plot.eps\", bar_plot, unit=\"in\", height=3.25, width = 3.25)"
  },
  {
    "objectID": "data_viz_tutorial.html",
    "href": "data_viz_tutorial.html",
    "title": "Practical session 2: R-tistic Insights- Visualising your data in R",
    "section": "",
    "text": "Call the data in\nCreate a new variable vaccinated that indicates if an individual is fully vaccinated (dose2) or not. (Tip: use mutate and ifelse)\nPlot a scatterplot showing the relationship between age and date. Use the new variable vaccinated variable to color the points using the colour hex #1369FF and #00B556. (Tip: Use the command scale_colour_manual)\nNext try using the date_dose3 instead of date. Anything interesting?\n\n\n\n\n\nCreate a line chart to represent the cumulative number of vaccinations by dose over time.\nSelect all the date_doseX, and state\nPivot the data into long form (Tip: use the pivot_long function) and count the number of dose given on each date\nComplete the series of dates using complete\nPlot the the different doses by date across time and facet by state\nColour date_dose3= #A3D2D5. Maintain the other 2 colours.\nApply a pre-set theme\n\n\n\n\n\nCall data in\nReplace all empty cells with NA in column brand2\nGroup by state and brand2 and summarise the number of groups in each brand, state\nPlot a box plot on the distribution of deaths by brand2\nTitle should be “Number of Deaths by Vaccine Brand and Date” with x-axis labels of “Vaccine Brand” and y-axis labels of “Number of Deaths” (Tip: Use labs)\n\n\n\n\n\nCall in data\nSelect on state, malaysian, bid\nFactorise the variable\nBuild a grouped bar chart by state and bid status\nFacet wrap by malaysian\nTitle should be “Deaths by State, Brought-in-Dead Status, and Malaysian Status” with x-axis labels of “State” and y-axis labels of “Number of Deaths”. Legend label should be “Brought-in-Dead Status”.\nApply theme_minimal and adjust the x-axis text to be perpendicular (90 degrees) to the axis (Tip: Use theme (axis.text.x=element_text()))\nWhat should you change to transform this into a stacked bar chart?\n\n\n\n\n\nEasy peasy lemon squesy- just save all of the above 4 plots. (Tip: use ggsave())\nHow can we change output format, quality, size"
  },
  {
    "objectID": "data_wranggling.html",
    "href": "data_wranggling.html",
    "title": "Untangling Data with Tidyverse: Data wranggling in R",
    "section": "",
    "text": "Data cleaning is arguably the most crucial step in the data analysis pipeline because it directly impacts the accuracy and reliability of insights drawn from the data.\nWithout thoroughly cleaning the data, we might be working with incorrect, inconsistent, or irrelevant information, leading to potentially faulty conclusions. Data cleaning ensures the data is correctly formatted, accurate, complete, and ready for analysis. It involves dealing with missing values, removing duplicates, correcting inconsistencies, and handling outliers. Only after a rigorous data cleaning process can we trust that our analysis or model will give us meaningful, actionable insights.\nThus, while it can be a time-consuming process, skipping or skimping on data cleaning can lead to wasting even more time and resources downstream, as we try to interpret misleading results or troubleshoot models that aren’t performing as expected."
  },
  {
    "objectID": "data_wranggling.html#data-frames",
    "href": "data_wranggling.html#data-frames",
    "title": "Untangling Data with Tidyverse: Data wranggling in R",
    "section": "Data Frames",
    "text": "Data Frames\nThe data frame (or data.frame) is a key data structure in statistics and in R.\nThe basic structure of a data frame is that there is one observation per row and each column represents a variable, a measure, feature, or characteristic of that observation."
  },
  {
    "objectID": "data_wranggling.html#tibbles",
    "href": "data_wranggling.html#tibbles",
    "title": "Untangling Data with Tidyverse: Data wranggling in R",
    "section": "Tibbles",
    "text": "Tibbles\nAnother type of data structure that we need to discuss is called the tibble! It’s best to think of tibbles as an updated and stylish version of the data.frame.\nBefore we go any further, tibbles are data frames, but they have some new bells and whistles to make your life easier.\n\nHow tibbles differ from data.frame\n\nInput type remains unchanged - data.frame is notorious for treating strings as factors; this will not happen with tibbles\nVariable names remain unchanged - In base R, creating data.frames will remove spaces from names, converting them to periods or add “x” before numeric column names. Creating tibbles will not change variable (column) names.\nThere are no row.names() for a tibble - Tidy data requires that variables be stored in a consistent way, removing the need for row names.\nTibbles print first ten rows and columns that fit on one screen - Printing a tibble to screen will never print the entire huge data frame out. By default, it just shows what fits to your screen.\n\n\n\nConverting to data.frame or tibble\nUse the as.data.frame() or as_tibble()\n\n\nCalling in some data\nFor the purposes of this session lets utilise the Malaysian COVID-19 deaths linelinest maintained by the Ministry of Health on their Github page. Codes for each column are as follows:\n\ndate: yyyy-mm-dd format; date of death\ndate_announced: date on which the death was announced to the public (i.e. registered in the public linelist)\ndate_positive: date of positive sample\ndate_doseN: date of the individual’s first/second/third dose (if any)\nbrandN: p = Pfizer, s = Sinovac, a = AstraZeneca, c = Cansino, m = Moderna, h = Sinopharm, j = Janssen, u = unverified (pending sync with VMS)\nstate: state of residence\nage: age as an integer; note that it is possible for age to be 0, denoting infants less than 6 months old\nmale: binary variable with 1 denoting male and 0 denoting female\nbid: binary variable with 1 denoting brought-in-dead and 0 denoting an inpatient death\nmalaysian: binary variable with 1 denoting Malaysian and 0 denoting non-Malaysian\ncomorb: binary variable with 1 denoting that the individual has comorbidities and 0 denoting no comorbidities declared\n\nLets call in the data:\n\nc19_df <- read.csv(\"https://raw.githubusercontent.com/MoH-Malaysia/covid19-public/main/epidemic/linelist/linelist_deaths.csv\")\n\nCheck the data structure\n\nstr(c19_df)\n\n'data.frame':   37152 obs. of  15 variables:\n $ date          : chr  \"2020-03-17\" \"2020-03-17\" \"2020-03-20\" \"2020-03-21\" ...\n $ date_announced: chr  \"2020-03-17\" \"2020-03-17\" \"2020-03-20\" \"2020-03-21\" ...\n $ date_positive : chr  \"2020-03-12\" \"2020-03-15\" \"2020-03-11\" \"2020-03-13\" ...\n $ date_dose1    : chr  \"\" \"\" \"\" \"\" ...\n $ date_dose2    : chr  \"\" \"\" \"\" \"\" ...\n $ date_dose3    : chr  \"\" \"\" \"\" \"\" ...\n $ brand1        : chr  \"\" \"\" \"\" \"\" ...\n $ brand2        : chr  \"\" \"\" \"\" \"\" ...\n $ brand3        : chr  \"\" \"\" \"\" \"\" ...\n $ state         : chr  \"Johor\" \"Sarawak\" \"Sabah\" \"Melaka\" ...\n $ age           : int  34 60 58 50 80 39 57 69 48 73 ...\n $ male          : int  1 1 1 1 0 0 1 1 1 1 ...\n $ bid           : int  0 0 0 0 1 0 0 0 0 0 ...\n $ malaysian     : int  1 1 1 1 1 1 1 1 1 1 ...\n $ comorb        : int  1 1 1 1 1 1 1 1 1 1 ...\n\ndim(c19_df)\n\n[1] 37152    15"
  },
  {
    "objectID": "data_wranggling.html#pivoting-in-r",
    "href": "data_wranggling.html#pivoting-in-r",
    "title": "Untangling Data with Tidyverse: Data wranggling in R",
    "section": "Pivoting in R",
    "text": "Pivoting in R\nThe tidyr package includes functions to transfer a data frame between long and wide.\n\nWide format data tends to have different attributes or variables describing an observation placed in separate columns.\nLong format data tends to have different attributes encoded as levels of a single variable, followed by another column that contains values of the observation at those different levels.\n\nLets create a sample set based on the deaths dataset focussing only on brand2 uptake over time.\n\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `across(where(is.character), na_if, \"\")`.\nCaused by warning:\n! The `...` argument of `across()` is deprecated as of dplyr 1.1.0.\nSupply arguments directly to `.fns` through an anonymous function instead.\n\n  # Previously\n  across(a:b, mean, na.rm = TRUE)\n\n  # Now\n  across(a:b, \\(x) mean(x, na.rm = TRUE))\n\n\n`summarise()` has grouped output by 'date'. You can override using the\n`.groups` argument.\n\n\n\npivot_wider()\nThe pivot_wider() function is less commonly needed to tidy data as compared to its sister pivot_longer. It can, however, be useful for creating summary tables. As out sample dataset is already in long form- for the sake of this example we will pivot_wider first.\n\ndose2_df <- dose2_df %>%\n  pivot_wider(id_cols=\"date\",\n              names_from = \"brand2\",\n              values_from = \"count\")\n\n\n\n\n\n\n\nTippy-tip\n\n\n\nYou use the kable() function in dplyr to make nicer looking html tables\n\ndose2_df %>%\n  mutate_all(~replace_na(., 0)) %>%\n  head(10) %>%\n  knitr::kable(format=\"html\", caption = \"Vaccinations among COVID-19 fatalities by Brand\") %>% kableExtra::kable_minimal()\n\n`mutate_all()` ignored the following grouping variables:\n• Column `date`\nℹ Use `mutate_at(df, vars(-group_cols()), myoperation)` to silence the message.\n\n\n\n\nVaccinations among COVID-19 fatalities by Brand\n \n  \n    date \n    unvaccinated \n    Pfizer \n    Sinovac \n    Pending VMS sync \n    AstraZeneca \n    Moderna \n    Sinopharm \n  \n \n\n  \n    2020-03-17 \n    2 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n  \n  \n    2020-03-20 \n    1 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n  \n  \n    2020-03-21 \n    4 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n  \n  \n    2020-03-22 \n    4 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n  \n  \n    2020-03-23 \n    5 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n  \n  \n    2020-03-24 \n    2 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n  \n  \n    2020-03-25 \n    3 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n  \n  \n    2020-03-26 \n    5 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n  \n  \n    2020-03-27 \n    2 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n  \n  \n    2020-03-28 \n    6 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n  \n\n\n\n\n\n\n\n\n\npivot_longer()\nEven if your data is in a tidy format, pivot_longer() is useful for pulling data together to take advantage of faceting, or plotting separate plots based on a grouping variable.\n\ndose2_df %>%\n  pivot_longer(-date, \n               names_to = \"brand2\",\n               values_to = \"count\")\n\n# A tibble: 7,028 × 3\n# Groups:   date [1,004]\n   date       brand2           count\n   <chr>      <chr>            <int>\n 1 2020-03-17 unvaccinated         2\n 2 2020-03-17 Pfizer              NA\n 3 2020-03-17 Sinovac             NA\n 4 2020-03-17 Pending VMS sync    NA\n 5 2020-03-17 AstraZeneca         NA\n 6 2020-03-17 Moderna             NA\n 7 2020-03-17 Sinopharm           NA\n 8 2020-03-20 unvaccinated         1\n 9 2020-03-20 Pfizer              NA\n10 2020-03-20 Sinovac             NA\n# ℹ 7,018 more rows\n\n\n\n\nseparate() and unite()\nThe same tidyr package also contains two useful functions:\n\nunite(): combine contents of two or more columns into a single column\nseparate(): separate contents of a column into two or more columns\n\nFirst, we combine the first three columns into one new column using unite().\n\nc19_df %>% select(brand1, brand2, brand3) %>%\n  unite(col=\"profile\", \n        brand1:brand3, \n        sep=\"_\") %>%\n  tail(10)\n\n                                  profile\n37143                                  __\n37144                                  __\n37145              Sinovac_Sinovac_Pfizer\n37146                      Pfizer_Pfizer_\n37147                                  __\n37148                Pfizer_Pfizer_Pfizer\n37149                Pfizer_Pfizer_Pfizer\n37150 AstraZeneca_AstraZeneca_AstraZeneca\n37151                                  __\n37152                    Sinovac_Sinovac_\n\n\nNext, we show how to separate the columns into three separate columns using separate() using the col, into and sep arguments.\n\nc19_df %>% select(brand1, brand2, brand3) %>%\n  unite(col=\"profile\", \n        brand1:brand3, \n        sep=\"_\") %>% \n  select(profile) %>%\n  separate(col=\"profile\", \n           into=c(\"brand1\", \"brand2\", \"brand3\"), \n           sep=\"_\") %>% \n  tail(10)\n\n           brand1      brand2      brand3\n37143                                    \n37144                                    \n37145     Sinovac     Sinovac      Pfizer\n37146      Pfizer      Pfizer            \n37147                                    \n37148      Pfizer      Pfizer      Pfizer\n37149      Pfizer      Pfizer      Pfizer\n37150 AstraZeneca AstraZeneca AstraZeneca\n37151                                    \n37152     Sinovac     Sinovac"
  },
  {
    "objectID": "data_wranggling.html#mutating-joins",
    "href": "data_wranggling.html#mutating-joins",
    "title": "Untangling Data with Tidyverse: Data wranggling in R",
    "section": "Mutating joins",
    "text": "Mutating joins\nThe dplyr package provides a set of functions for joining two data frames into a single data frame based on a set of key columns.\nThere are several functions in the *_join() family.\n\nThese functions all merge together two data frames\nThey differ in how they handle observations that exist in one but not both data frames.\n\nHere, are the four functions from this family that you will likely use the most often:\n\n\n\n\n \n  \n    Function \n    What it includes in merged data frame \n  \n \n\n  \n    `left_join()` \n    Includes all observations in the left data frame, whether or not there is a match in the right data frame \n  \n  \n    `right_join()` \n    Includes all observations in the right data frame, whether or not there is a match in the left data frame \n  \n  \n    `inner_join()` \n    Includes only observations that are in both data frames \n  \n  \n    `full_join()` \n    Includes all observations from both data frames \n  \n\n\n\n\n\n\n[Source from R for Data Science]\nSuppose we want to create a table that combines the information about COVID-19 deaths (c19_df) with the information about the expenditure (hies_df) at each state.\nFirst lets take c19_df and aggregate it at the state level.\n\nstate_df <- c19_df %>% select(state) %>%\n  group_by(state) %>%\n  summarise(deaths=n())\n\nLets call in an external object to join\n\nhies_df <- read.csv(\"https://raw.githubusercontent.com/dosm-malaysia/data-open/main/datasets/economy/hies_2019.csv\")\n\nLets look at the data\n\ntable(hies_df$area_type)\n\n\n district       dun parliment     state \n      160       600       222        16 \n\n\n\nLeft Join\nWe can use the left_join() function to merge the state_df and hies_df datasets.\n\nleft_join(x = state_df, y = hies_df, by = join_by(state==area))\n\n# A tibble: 20 × 7\n   state        deaths area_type income_mean expenditure_mean  gini poverty_rate\n   <chr>         <int> <chr>           <int>            <int> <dbl>        <dbl>\n 1 Johor          4740 state            8013             4793 0.366          3.9\n 2 Kedah          2756 state            5522             3359 0.354          8.8\n 3 Kelantan       1428 state            4874             3223 0.378         12.4\n 4 Melaka         1213 state            7741             4955 0.383          3.9\n 5 Negeri Semb…   1546 state            6707             4350 0.391          4.3\n 6 Pahang         1037 state            5667             3652 0.33           4.3\n 7 Perak          2164 state            5645             3564 0.377          7.3\n 8 Perlis          199 state            5476             3468 0.334          3.9\n 9 Perlis          199 district         5476             3468 0.334          3.9\n10 Pulau Pinang   2085 state            7774             4630 0.359          1.9\n11 Sabah          3211 state            5745             2792 0.397         19.5\n12 Sarawak        1795 state            5959             3448 0.387          9  \n13 Selangor      11024 state           10827             5830 0.393          1.2\n14 Terengganu      905 state            6815             4336 0.335          6.1\n15 W.P. Kuala …   2861 state           13257             6913 0.35           0.2\n16 W.P. Kuala …   2861 district        13257             6913 0.35           0.2\n17 W.P. Labuan     159 state            8319             4097 0.333          3.1\n18 W.P. Labuan     159 district         8319             4097 0.333          3.1\n19 W.P. Putraj…     29 state           12840             7980 0.361          0.4\n20 W.P. Putraj…     29 district        12840             7980 0.361          0.4\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe by argument indicates the column (or columns) that the two tables have in common. One more than one joining variable an be used for this statement\n\n\nQuite obviously the join should give you the total number of rows on the left side of your statement. Note in the above case there are 20 rows because there are four districts with the same name as states.\n\n\nInner Join\nThe inner_join() function only retains the rows of both tables that have corresponding values. Here we can see the difference.\n\ninner_join(x = state_df, y = hies_df, by = join_by(state==area))\n\n# A tibble: 20 × 7\n   state        deaths area_type income_mean expenditure_mean  gini poverty_rate\n   <chr>         <int> <chr>           <int>            <int> <dbl>        <dbl>\n 1 Johor          4740 state            8013             4793 0.366          3.9\n 2 Kedah          2756 state            5522             3359 0.354          8.8\n 3 Kelantan       1428 state            4874             3223 0.378         12.4\n 4 Melaka         1213 state            7741             4955 0.383          3.9\n 5 Negeri Semb…   1546 state            6707             4350 0.391          4.3\n 6 Pahang         1037 state            5667             3652 0.33           4.3\n 7 Perak          2164 state            5645             3564 0.377          7.3\n 8 Perlis          199 state            5476             3468 0.334          3.9\n 9 Perlis          199 district         5476             3468 0.334          3.9\n10 Pulau Pinang   2085 state            7774             4630 0.359          1.9\n11 Sabah          3211 state            5745             2792 0.397         19.5\n12 Sarawak        1795 state            5959             3448 0.387          9  \n13 Selangor      11024 state           10827             5830 0.393          1.2\n14 Terengganu      905 state            6815             4336 0.335          6.1\n15 W.P. Kuala …   2861 state           13257             6913 0.35           0.2\n16 W.P. Kuala …   2861 district        13257             6913 0.35           0.2\n17 W.P. Labuan     159 state            8319             4097 0.333          3.1\n18 W.P. Labuan     159 district         8319             4097 0.333          3.1\n19 W.P. Putraj…     29 state           12840             7980 0.361          0.4\n20 W.P. Putraj…     29 district        12840             7980 0.361          0.4\n\n\nDoes inner_join give different results to left_join in the above example?\n\n\nRight Join\nThe right_join() function is like the left_join() function except that it gives priority to the “right” hand argument.\n\nright_join(x = state_df, y = hies_df, by = join_by(state==area))\n\n# A tibble: 998 × 7\n   state        deaths area_type income_mean expenditure_mean  gini poverty_rate\n   <chr>         <int> <chr>           <int>            <int> <dbl>        <dbl>\n 1 Johor          4740 state            8013             4793 0.366          3.9\n 2 Kedah          2756 state            5522             3359 0.354          8.8\n 3 Kelantan       1428 state            4874             3223 0.378         12.4\n 4 Melaka         1213 state            7741             4955 0.383          3.9\n 5 Negeri Semb…   1546 state            6707             4350 0.391          4.3\n 6 Pahang         1037 state            5667             3652 0.33           4.3\n 7 Perak          2164 state            5645             3564 0.377          7.3\n 8 Perlis          199 state            5476             3468 0.334          3.9\n 9 Perlis          199 district         5476             3468 0.334          3.9\n10 Pulau Pinang   2085 state            7774             4630 0.359          1.9\n# ℹ 988 more rows\n\n\nWhat about now?"
  },
  {
    "objectID": "data_wranggling.html#acknowledgements",
    "href": "data_wranggling.html#acknowledgements",
    "title": "Untangling Data with Tidyverse: Data wranggling in R",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nMaterial for this lecture was borrowed and adopted from\n\nhttps://stephaniehicks.com/jhustatcomputing2022/\nThe Epidemiologist R Handbook\nhttps://rafalab.github.io/dsbook\nhttps://rmd4sci.njtierney.com"
  },
  {
    "objectID": "data_wranggling.html#additional-resources",
    "href": "data_wranggling.html#additional-resources",
    "title": "Untangling Data with Tidyverse: Data wranggling in R",
    "section": "Additional Resources",
    "text": "Additional Resources\n\n\n\n\n\n\nTip\n\n\n\n\nhttps://r4ds.had.co.nz/tibbles.html\nhttps://jhudatascience.org/tidyversecourse/wrangle-data.html#data-wrangling\ndplyr cheat sheet from RStudio"
  },
  {
    "objectID": "data_wranggling_solutions.html",
    "href": "data_wranggling_solutions.html",
    "title": "Practical session 1: Untangling Data with Tidyverse: Data wranggling in R",
    "section": "",
    "text": "Task 1: Calculate the average age for deaths by state and find the state with the highest average age.\nSteps:\n\nFirst, we need to group the data by state.\nThen, we can summarize the average age per state using summarise.\nUse arrange to sort the average age in descending order to find the state with the highest average age.\n\nSolution:\n\nc19_df %>% \n  group_by(state) %>%\n  summarise(avg_age = mean(age, na.rm = TRUE)) %>%\n  arrange(desc(avg_age))\n\n# A tibble: 16 × 2\n   state             avg_age\n   <chr>               <dbl>\n 1 Perlis               68.1\n 2 Sarawak              68.1\n 3 Perak                66.9\n 4 Kelantan             66.7\n 5 Pulau Pinang         66.0\n 6 Sabah                65.4\n 7 Terengganu           64.9\n 8 W.P. Putrajaya       64.7\n 9 Negeri Sembilan      64.5\n10 Pahang               63.2\n11 Kedah                63.1\n12 Melaka               62.2\n13 W.P. Kuala Lumpur    61.7\n14 Johor                60.9\n15 Selangor             59.4\n16 W.P. Labuan          59.3\n\n\n\n\nTask 2: Determine the proportion of male to female deaths in each state.\nSteps:\n\nUsing mutate, create a new column called gender using ifelse to convert the male column to ‘Male’ and ‘Female’.\nGroup the data by state and gender.\nSummarise the count of each gender in each state.\nCreate a new column with the proportion of each gender in each state.\n\nSolution:\n\nc19_df %>%\n  mutate(gender = ifelse(male == 1, \"Male\", \"Female\")) %>%\n  group_by(state, gender) %>%\n  summarise(count = n()) %>%\n  mutate(proportion = count / sum(count))\n\n`summarise()` has grouped output by 'state'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 32 × 4\n# Groups:   state [16]\n   state           gender count proportion\n   <chr>           <chr>  <int>      <dbl>\n 1 Johor           Female  2096      0.442\n 2 Johor           Male    2644      0.558\n 3 Kedah           Female  1280      0.464\n 4 Kedah           Male    1476      0.536\n 5 Kelantan        Female   707      0.495\n 6 Kelantan        Male     721      0.505\n 7 Melaka          Female   529      0.436\n 8 Melaka          Male     684      0.564\n 9 Negeri Sembilan Female   675      0.437\n10 Negeri Sembilan Male     871      0.563\n# ℹ 22 more rows\n\n\n\n\nTask 3: Determine the total number of deaths by month and year.\nSteps:\n\nConvert the date column to Date type if it’s not already.\nUse mutate to create new columns year and month using the year and month functions from the lubridate package.\nGroup the data by year and month.\nUse summarise to count the number of deaths.\n\nSolution:\n\nc19_df %>%\n  mutate(date = as.Date(date),\n         year = year(date),\n         month = month(date)) %>%\n  group_by(year, month) %>%\n  summarise(deaths = n())\n\n`summarise()` has grouped output by 'year'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 40 × 3\n# Groups:   year [4]\n    year month deaths\n   <dbl> <dbl>  <int>\n 1  2020     3     48\n 2  2020     4     55\n 3  2020     5     12\n 4  2020     6      6\n 5  2020     7      4\n 6  2020     8      3\n 7  2020     9     10\n 8  2020    10    129\n 9  2020    11    116\n10  2020    12    133\n# ℹ 30 more rows\n\n\n\n\nTask 4: Determine if comorbidities are more common in Malaysian or non-Malaysian deaths.\nSteps:\n\nCreate a new column nationality that categorizes malaysian into ‘Malaysian’ and ‘Non-Malaysian’ using mutate and ifelse.\nGroup by nationality.\nSummarise the average comorbidity rate (comorb).\n\nSolution:\n\nc19_df %>%\n  mutate(nationality = ifelse(malaysian == 1, \"Malaysian\", \"Non-Malaysian\")) %>%\n  group_by(nationality) %>%\n  summarise(avg_comorb = mean(comorb, na.rm = TRUE))\n\n# A tibble: 2 × 2\n  nationality   avg_comorb\n  <chr>              <dbl>\n1 Malaysian          0.827\n2 Non-Malaysian      0.461\n\n\n\n\nTask 5: Find out the most common vaccine brand combination that was administered.\nSteps:\n\nUse mutate to create a new column brands_combo that concatenates brand1, brand2, and brand3.\nfilter to keep only those rows where brands_combo is not empty.\nGroup by brands_combo.\nCount the number of occurrences for each vaccine brand combination using summarise.\n\nSolution:\n\nc19_df %>%\n  unite(col=\"profile\", \n        brand1:brand3, \n        sep=\"_\")  %>%\n  filter(profile != \"--\") %>%\n  group_by(profile) %>%\n  summarise(count = n()) %>%\n  arrange(desc(count))\n\n# A tibble: 32 × 2\n   profile                  count\n   <chr>                    <int>\n 1 __                       22437\n 2 Sinovac_Sinovac_          4693\n 3 Pfizer_Pfizer_            2733\n 4 Sinovac__                 2672\n 5 Pfizer__                  2141\n 6 AstraZeneca__              707\n 7 Pfizer_Pfizer_Pfizer       591\n 8 Sinovac_Sinovac_Pfizer     548\n 9 AstraZeneca_AstraZeneca_   242\n10 Sinovac_Sinovac_Sinovac    145\n# ℹ 22 more rows"
  },
  {
    "objectID": "data_wranggling_tutorial.html",
    "href": "data_wranggling_tutorial.html",
    "title": "Practical session 1: Untangling Data with Tidyverse: Data wranggling in R",
    "section": "",
    "text": "Task 1: Calculate the average age for deaths by state and find the state with the highest average age.\nSteps:\n\nFirst, we need to group the data by state.\nThen, we can summarize the average age per state using summarise.\nUse arrange to sort the average age in descending order to find the state with the highest average age.\n\n\n\nTask 2: Determine the proportion of male to female deaths in each state.\nSteps:\n\nUsing mutate, create a new column called gender using ifelse to convert the male column to ‘Male’ and ‘Female’.\nGroup the data by state and gender.\nSummarise the count of each gender in each state.\nCreate a new column with the proportion of each gender in each state.\n\n\n\nTask 3: Determine the total number of deaths by month and year.\nSteps:\n\nConvert the date column to Date type if it’s not already.\nUse mutate to create new columns year and month using the year and month functions from the lubridate package.\nGroup the data by year and month.\nUse summarise to count the number of deaths.\n\n\n\nTask 4: Determine if comorbidities are more common in Malaysian or non-Malaysian deaths.\nSteps:\n\nCreate a new column nationality that categorizes malaysian into ‘Malaysian’ and ‘Non-Malaysian’ using mutate and ifelse.\nGroup by nationality.\nSummarise the average comorbidity rate (comorb).\n\n\n\nTask 5: Find out the most common vaccine brand combination that was administered.\nSteps:\n\nUse mutate to create a new column brands_combo that concatenates brand1, brand2, and brand3.\nfilter to keep only those rows where brands_combo is not empty.\nGroup by brands_combo.\nCount the number of occurrences for each vaccine brand combination using summarise."
  },
  {
    "objectID": "inferential_stats.html",
    "href": "inferential_stats.html",
    "title": "Powering up! Descriptive Statistics and Inferential Tests",
    "section": "",
    "text": "Descriptive and inferential statistics form the bedrock of any complex analysis. Descriptive statistics summarize raw data and provide a snapshot of the sample’s features, revealing trends, patterns, and distributions, essential for making the data comprehensible. Inferential statistics allow for conclusions or predictions about a larger population from the sampled data, providing the necessary basis for hypothesis testing. Together, they provide an initial understanding of data, and an informed context for the application of more complex statistical or machine learning techniques.\n\n\n\n\n\nAs we mentioned in the Introduction- there are many ways to skin a cat in R.\n\ntidyverse() for Describing data\nAs we learned yesterday- the tidyverse has revolutionised data wranggling and can be extended likewise into the realm of descriptive statistics. Creating tables with dplyr functions summarise() and count() is a useful approach to calculating summary statistics, summarize by group, or pass tables to ggplot() or flextable(). In yesterdays tutorial we briefly did visit this, but we will extend on this in the next 10 minutes or so before transitioning into a simpler more efficient way of describing data in R.\nLets get some important packages loaded\n\nrequired_packages <- c(\"tidyverse\", \"lubridate\", \"gtsummary\", \"rstatix\", \"janitor\", \"corrr\")\nnot_installed <- required_packages[!(required_packages %in% installed.packages()[ , \"Package\"])]    \nif(length(not_installed)) install.packages(not_installed)                                           \nsuppressWarnings(lapply(required_packages, require, character.only = TRUE))\n\nLoading required package: tidyverse\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\nLoading required package: gtsummary\n\nLoading required package: rstatix\n\n\nAttaching package: 'rstatix'\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\nLoading required package: janitor\n\n\nAttaching package: 'janitor'\n\n\nThe following object is masked from 'package:rstatix':\n\n    make_clean_names\n\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\n\nLoading required package: corrr\n\n\n\nImporting some data\nLets call in the data:\n\nc19_df <- read.csv(\"https://raw.githubusercontent.com/MoH-Malaysia/covid19-public/main/epidemic/linelist/linelist_deaths.csv\")\n\nJust to be consistent we what I said yesterday- before diving into the data always always skim the data first to get a quick feels\n\nc19_df %>% \n  skimr::skim()\n\n\nData summary\n\n\nName\nPiped data\n\n\nNumber of rows\n37152\n\n\nNumber of columns\n15\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n10\n\n\nnumeric\n5\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\ndate\n0\n1\n10\n10\n0\n1004\n0\n\n\ndate_announced\n0\n1\n10\n10\n0\n1000\n0\n\n\ndate_positive\n0\n1\n10\n10\n0\n999\n0\n\n\ndate_dose1\n0\n1\n0\n10\n22437\n298\n0\n\n\ndate_dose2\n0\n1\n0\n10\n28034\n267\n0\n\n\ndate_dose3\n0\n1\n0\n10\n35719\n161\n0\n\n\nbrand1\n0\n1\n0\n16\n22437\n8\n0\n\n\nbrand2\n0\n1\n0\n16\n28034\n7\n0\n\n\nbrand3\n0\n1\n0\n16\n35719\n6\n0\n\n\nstate\n0\n1\n5\n17\n0\n16\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nage\n0\n1\n62.65\n16.59\n0\n51\n64\n75\n130\n▁▃▇▃▁\n\n\nmale\n0\n1\n0.58\n0.49\n0\n0\n1\n1\n1\n▆▁▁▁▇\n\n\nbid\n0\n1\n0.21\n0.41\n0\n0\n0\n0\n1\n▇▁▁▁▂\n\n\nmalaysian\n0\n1\n0.89\n0.31\n0\n1\n1\n1\n1\n▁▁▁▁▇\n\n\ncomorb\n0\n1\n0.79\n0.41\n0\n1\n1\n1\n1\n▂▁▁▁▇\n\n\n\n\n\n\n\nGet counts\nThe most simple function to apply within summarise() is n(). Leave the parentheses empty to count the number of rows. You may have seen this being used several times yesterday. Let\n\nc19_df %>%                 # begin with linelist\n  summarise(n_rows = n())    # return new summary dataframe with column n_rows\n\n  n_rows\n1  37152\n\n\nLets try and stratify that by nationality and BID status:\n\nc19_df %>% \n  group_by(malaysian, bid) %>%     # group data by unique values in column age_cat\n  summarise(n_rows = n())   # return number of rows *per group*\n\n`summarise()` has grouped output by 'malaysian'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 4 × 3\n# Groups:   malaysian [2]\n  malaysian   bid n_rows\n      <int> <int>  <int>\n1         0     0   1958\n2         0     1   2076\n3         1     0  27288\n4         1     1   5830\n\n\nThe above command can be shortened by using the count() function instead. count() does the following:\n\nGroups the data by the columns provided to it\nSummarises them with n() (creating column n)\nUn-groups the data\n\n\nc19_df %>%\n  count(malaysian, bid)\n\n  malaysian bid     n\n1         0   0  1958\n2         0   1  2076\n3         1   0 27288\n4         1   1  5830\n\n\n\n\nProportions\nProportions can be added by piping the table to mutate() to create a new column. Define the new column as the counts column (n by default) divided by the sum() of the counts column (this will return a proportion).\n\nbid_summary <- c19_df %>% \n  count(malaysian, bid) %>%                     # group and count by gender (produces \"n\" column)\n  mutate(                                # create percent of column - note the denominator\n    percent = round((n / sum(n))*100,2)) \n\n# print\nbid_summary\n\n  malaysian bid     n percent\n1         0   0  1958    5.27\n2         0   1  2076    5.59\n3         1   0 27288   73.45\n4         1   1  5830   15.69\n\n\n\n\n\n\n\n\nTip\n\n\n\nUsing these structure we can very easily modify these summary statistics using ggplot() or html tables kable() or presentation ready tables using flextable() (flextable is not covered in this course but you can check it out here). An example of a plot is as follows:\n\nc19_df %>% \n  count(malaysian, bid) %>%                     \n  mutate(percent = round((n / sum(n))*100,2)) %>%     \n  ggplot()+                       # pass new data frame to ggplot\n    geom_col(                     # create bar plot\n      mapping = aes(   \n        x = malaysian,            # map outcome to x-axis\n        fill = bid,               # map age_cat to the fill\n        y = percent))             # map the counts column `n` to the height\n\n\n\n\nOr a nice little table summary:\n\nc19_df %>% \n  count(malaysian, bid) %>%\n  mutate(malaysian = factor(malaysian,\n                               levels=c(\"0\",\"1\"),\n                               labels=c(\"non-Malaysian\", \"Malaysian\")),\n         bid = factor(bid,\n                               levels=c(\"0\",\"1\"),\n                               labels=c(\"Hospital\", \"BID\")),) %>%\n  mutate(percent = round((n / sum(n))*100,2))%>%\n  knitr::kable(format=\"html\", caption = \"COVID-19 fatalities by Nationality and Place of Death\",) %>% kableExtra::kable_minimal()\n\n\n\nCOVID-19 fatalities by Nationality and Place of Death\n \n  \n    malaysian \n    bid \n    n \n    percent \n  \n \n\n  \n    non-Malaysian \n    Hospital \n    1958 \n    5.27 \n  \n  \n    non-Malaysian \n    BID \n    2076 \n    5.59 \n  \n  \n    Malaysian \n    Hospital \n    27288 \n    73.45 \n  \n  \n    Malaysian \n    BID \n    5830 \n    15.69 \n  \n\n\n\n\n\n\n\n\n\nSummary statistics\nOne major advantage of dplyr and summarise() is the ability to return more advanced statistical summaries like median(), mean(), max(), min(), sd() (standard deviation), and percentiles. You can also use sum() to return the number of rows that meet certain logical criteria. As above, these outputs can be produced for the whole data frame set, or by group.\nThe syntax is the same - within the summarise() parentheses you provide the names of each new summary column followed by an equals sign and a statistical function to apply. Within the statistical function, give the column(s) to be operated on and any relevant arguments (e.g. na.rm = TRUE for most mathematical functions).\nYou can also use sum() to return the number of rows that meet a logical criteria. The expression within is counted if it evaluates to TRUE. For example:\n\nsum(age_years < 18, na.rm=T)\n\nsum(gender == \"male\", na.rm=T)\n\nsum(response %in% c(\"Likely\", \"Very Likely\"))\n\nBelow, c19_df data are summarised to describe the days delay from death to announcement (column days_death_state), by state.\n\nc19_df %>%                 # begin with linelist, save out as new object\n  group_by(state) %>%      # group all calculations by hospital\n  mutate(across(contains(\"date\"), ~as.Date(., format = \"%Y-%m-%d\")), #change character to dates\\ fromat\n         days_death_state=date_announced-date) %>% # calculate the delay for each death\n  summarise(                                                         # only the below summary columns will be returned\n    deaths       = n(),                                                # number of rows per group\n    delay_max   = max(days_death_state, na.rm = T),                    # max delay\n    delay_mean  = round(mean(days_death_state, na.rm=T), digits = 1),  # mean delay, rounded\n    delay_sd    = round(sd(days_death_state, na.rm = T), digits = 1),  # standard deviation of delays, rounded\n    delay_3     = sum(days_death_state >= 3, na.rm = T),               # number of rows with delay of 3 or more days\n    pct_delay_3 = scales::percent(delay_3 / deaths)                    # convert previously-defined delay column to percent (scales gives the % sign behind)\n  )\n\n# A tibble: 16 × 7\n   state             deaths delay_max delay_mean delay_sd delay_3 pct_delay_3\n   <chr>              <int> <drtn>    <drtn>        <dbl>   <int> <chr>      \n 1 Johor               4740 253 days   4.8 days      11.8    1987 42%        \n 2 Kedah               2756 338 days  10.0 days      18.6    1531 56%        \n 3 Kelantan            1428 153 days   7.5 days      12.5     920 64%        \n 4 Melaka              1213 386 days   5.2 days      15       460 38%        \n 5 Negeri Sembilan     1546 274 days   8.7 days      19.5     659 43%        \n 6 Pahang              1037 325 days   5.2 days      19       392 38%        \n 7 Perak               2164 178 days   4.0 days       9.4    1029 48%        \n 8 Perlis               199  16 days   2.5 days       2.4      67 34%        \n 9 Pulau Pinang        2085 396 days   3.7 days      10.9     958 46%        \n10 Sabah               3211 237 days   4.9 days       8.7    2062 64%        \n11 Sarawak             1795 167 days   4.5 days       9.6     900 50%        \n12 Selangor           11024 370 days  17.5 days      23.5    8688 79%        \n13 Terengganu           905 150 days   3.2 days       7       421 47%        \n14 W.P. Kuala Lumpur   2861 315 days  11.0 days      21.3    2026 71%        \n15 W.P. Labuan          159  14 days   1.3 days       1.3      13 8%         \n16 W.P. Putrajaya        29 388 days  20.9 days      71.6      14 48%        \n\n\n\n\n\n\n\n\nTip\n\n\n\n\nUse sum() with a logic statement to “count” rows that meet certain criteria (==)\n\nNote the use of na.rm = TRUE within mathematical functions like sum(), otherwise NA will be returned if there are any missing values\n\nUse the function percent() from the scales package to easily convert to percents\n\nSet accuracy = to 0.1 or 0.01 to ensure 1 or 2 decimal places respectively\n\n\nUse round() from base R to specify decimals\n\nTo calculate these statistics on the entire dataset, use summarise() without group_by()\n\nYou may create columns for the purposes of later calculations (e.g. denominators) that you eventually drop from your data frame with select().\n\n\n\n\n\nConditional statistics\nYou may want to return conditional statistics - e.g. the maximum of rows that meet certain criteria. This can be done by subsetting the column with brackets [ ].\n\nc19_df %>% \n  group_by(state) %>% \n  summarise(\n    max_age_msian = median(age[malaysian == \"1\"], na.rm = T),\n    max_age_non_msian = median(age[malaysian == \"0\"], na.rm = T)\n  )\n\n# A tibble: 16 × 3\n   state             max_age_msian max_age_non_msian\n   <chr>                     <dbl>             <dbl>\n 1 Johor                      64                45  \n 2 Kedah                      65                45  \n 3 Kelantan                   68                58  \n 4 Melaka                     64                42.5\n 5 Negeri Sembilan            67                45  \n 6 Pahang                     65                46  \n 7 Perak                      70                46  \n 8 Perlis                     71                44  \n 9 Pulau Pinang               70                45  \n10 Sabah                      69                59  \n11 Sarawak                    71                42  \n12 Selangor                   63                47  \n13 Terengganu                 67.5              50  \n14 W.P. Kuala Lumpur          66                47  \n15 W.P. Labuan                61                56  \n16 W.P. Putrajaya             68                NA  \n\n\n\n\nPercentiles\nPercentiles and quantiles in dplyr deserve a special mention. To return quantiles, use quantile() with the defaults or specify the value(s) you would like with probs =.\n\n# get default percentile values of age (0%, 25%, 50%, 75%, 100%)\nc19_df %>% \n  summarise(age_percentiles = quantile(age, na.rm = TRUE))\n\nWarning: Returning more (or less) than 1 row per `summarise()` group was deprecated in\ndplyr 1.1.0.\nℹ Please use `reframe()` instead.\nℹ When switching from `summarise()` to `reframe()`, remember that `reframe()`\n  always returns an ungrouped data frame and adjust accordingly.\n\n\n  age_percentiles\n1               0\n2              51\n3              64\n4              75\n5             130\n\n\nOr manually defined percentiles that are grouped\n\n# get manually-specified percentile values of age (5%, 50%, 75%, 98%)\nc19_df %>% \n  group_by(malaysian) %>%\n  summarise(\n    age_percentiles = quantile(\n      age,\n      probs = c(.05, 0.5, 0.75, 0.98), \n      na.rm=TRUE)\n    ) \n\nWarning: Returning more (or less) than 1 row per `summarise()` group was deprecated in\ndplyr 1.1.0.\nℹ Please use `reframe()` instead.\nℹ When switching from `summarise()` to `reframe()`, remember that `reframe()`\n  always returns an ungrouped data frame and adjust accordingly.\n\n\n`summarise()` has grouped output by 'malaysian'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 8 × 2\n# Groups:   malaysian [2]\n  malaysian age_percentiles\n      <int>           <dbl>\n1         0              30\n2         0              48\n3         0              56\n4         0              86\n5         1              35\n6         1              66\n7         1              76\n8         1              92\n\n\n\n\n\n\n\n\nTip\n\n\n\nDo keep in mind that there any many ways to skin the cat! And always there will be more efficient ways to do things as you progress through R- Here is an example from the rstatix package\n\nc19_df %>% \n  group_by(malaysian) %>%\n  rstatix::get_summary_stats(age, type = \"quantile\")\n\n# A tibble: 2 × 8\n  malaysian variable     n  `0%` `25%` `50%` `75%` `100%`\n      <int> <fct>    <dbl> <dbl> <dbl> <dbl> <dbl>  <dbl>\n1         0 age       4034     0    41    48    56    130\n2         1 age      33118     0    54    66    76    110\n\n\n\n\n\n\nacross() multiple columns\nYou can use summarise() across multiple columns using across(). This makes life easier when you want to calculate the same statistics for many columns. Place across() within summarise() and specify the following:\n\n.cols = as either a vector of column names c() or “tidyselect” helper functions (explained below)\n\n.fns = the function to perform (no parentheses) - you can provide multiple within a list()\n\n\nc19_df %>% \n  group_by(state) %>% \n  mutate(across(contains(\"date\"), ~as.Date(., format = \"%Y-%m-%d\")), #change character to dates\\ fromat\n         days_toAnnounce_state=date_announced-date,\n         day_toDeath_state=date-date_positive) %>%\n  summarise(across(.cols = c(day_toDeath_state, days_toAnnounce_state), # columns\n                   .fns = list(\"mean\" = mean, \"sd\" = sd),    # multiple functions \n                   na.rm=T))                                 # extra arguments\n\nWarning: There was 1 warning in `summarise()`.\nℹ In argument: `across(...)`.\nℹ In group 1: `state = \"Johor\"`.\nCaused by warning:\n! The `...` argument of `across()` is deprecated as of dplyr 1.1.0.\nSupply arguments directly to `.fns` through an anonymous function instead.\n\n  # Previously\n  across(a:b, mean, na.rm = TRUE)\n\n  # Now\n  across(a:b, \\(x) mean(x, na.rm = TRUE))\n\n\n# A tibble: 16 × 5\n   state      day_toDeath_state_mean day_toDeath_state_sd days_toAnnounce_stat…¹\n   <chr>      <drtn>                                <dbl> <drtn>                \n 1 Johor      5.563924 days                          9.17  4.796414 days        \n 2 Kedah      6.058418 days                          6.43  9.989115 days        \n 3 Kelantan   5.427871 days                          6.74  7.468487 days        \n 4 Melaka     7.693322 days                          9.28  5.209398 days        \n 5 Negeri Se… 6.683700 days                          6.99  8.657827 days        \n 6 Pahang     7.459016 days                         13.1   5.176471 days        \n 7 Perak      4.489372 days                          7.60  3.978281 days        \n 8 Perlis     6.015075 days                         10.0   2.457286 days        \n 9 Pulau Pin… 4.852278 days                          4.75  3.738129 days        \n10 Sabah      5.930551 days                         15.8   4.892245 days        \n11 Sarawak    5.973816 days                          9.05  4.523120 days        \n12 Selangor   7.434960 days                         12.1  17.509434 days        \n13 Terengganu 5.896133 days                          6.78  3.240884 days        \n14 W.P. Kual… 6.166375 days                         12.1  11.021671 days        \n15 W.P. Labu… 6.232704 days                          6.47  1.314465 days        \n16 W.P. Putr… 7.862069 days                          7.29 20.896552 days        \n# ℹ abbreviated name: ¹​days_toAnnounce_state_mean\n# ℹ 1 more variable: days_toAnnounce_state_sd <dbl>\n\n\nHere are those “tidyselect” helper functions you can provide to .cols = to select columns:\n\neverything() - all other columns not mentioned\n\nlast_col() - the last column\n\nwhere() - applies a function to all columns and selects those which are TRUE\n\nstarts_with() - matches to a specified prefix. Example: starts_with(\"date\")\nends_with() - matches to a specified suffix. Example: ends_with(\"_end\")\n\ncontains() - columns containing a character string. Example: contains(\"time\")\nmatches() - to apply a regular expression (regex). Example: contains(\"[pt]al\")\n\nnum_range() -\nany_of() - matches if column is named. Useful if the name might not exist. Example: any_of(date_onset, date_death, cardiac_arrest)\n\n\nc19_df %>% \n  group_by(state) %>%\n  summarise(across(\n    .cols = where(is.numeric),  # all numeric columns in the data frame\n    .fns = mean,\n    na.rm=T))\n\n# A tibble: 16 × 6\n   state               age  male   bid malaysian comorb\n   <chr>             <dbl> <dbl> <dbl>     <dbl>  <dbl>\n 1 Johor              60.9 0.558 0.150     0.923  0.802\n 2 Kedah              63.1 0.536 0.191     0.975  0.812\n 3 Kelantan           66.7 0.505 0.233     0.978  0.852\n 4 Melaka             62.2 0.564 0.166     0.964  0.823\n 5 Negeri Sembilan    64.5 0.563 0.133     0.948  0.829\n 6 Pahang             63.2 0.606 0.149     0.959  0.808\n 7 Perak              66.9 0.577 0.187     0.976  0.859\n 8 Perlis             68.1 0.568 0.121     0.980  0.915\n 9 Pulau Pinang       66.0 0.584 0.227     0.911  0.791\n10 Sabah              65.4 0.601 0.379     0.800  0.799\n11 Sarawak            68.1 0.581 0.199     0.987  0.930\n12 Selangor           59.4 0.592 0.216     0.830  0.740\n13 Terengganu         64.9 0.534 0.145     0.981  0.871\n14 W.P. Kuala Lumpur  61.7 0.585 0.256     0.799  0.659\n15 W.P. Labuan        59.3 0.591 0.277     0.824  0.686\n16 W.P. Putrajaya     64.7 0.690 0.103     1      0.793\n\n\n\n\n\ngtsummary() package\nDescriptives statistics approaches in R are numerous.\nI initially heavily utilised dplyr and the janitor (you can find a tutorial here) and tableone (you can find a tutorial here) packages which are both fantastic packages. More recently however, I discovered gtsummary. And lets just say its the bomb! Its my absolutely favourite package for descriptive analysis (and we will explore some of its other powerful extensions later).\n\nIf you want to print your summary statistics in a pretty, publication-ready graphic, you can use the gtsummary package and its function tbl_summary(). The code can seem complex at first, but the outputs look very nice and print to your RStudio Viewer panel as an HTML image. s\n\nSummary table\nThe default behavior of tbl_summary() is quite incredible - it takes the columns you provide and creates a summary table in one command. The function prints statistics appropriate to the column class: median and inter-quartile range (IQR) for numeric columns, and counts (%) for categorical columns. Missing values are converted to “Unknown”. Footnotes are added to the bottom to explain the statistics, while the total N is shown at the top.\n\nc19_df %>% \n  select(age, state, male, malaysian, bid) %>%  # keep only the columns of interest\n  tbl_summary()                                 # default\n\n\n\n\n\n  \n  \n    \n      Characteristic\n      N = 37,1521\n    \n  \n  \n    age\n64 (51, 75)\n    state\n\n        Johor\n4,740 (13%)\n        Kedah\n2,756 (7.4%)\n        Kelantan\n1,428 (3.8%)\n        Melaka\n1,213 (3.3%)\n        Negeri Sembilan\n1,546 (4.2%)\n        Pahang\n1,037 (2.8%)\n        Perak\n2,164 (5.8%)\n        Perlis\n199 (0.5%)\n        Pulau Pinang\n2,085 (5.6%)\n        Sabah\n3,211 (8.6%)\n        Sarawak\n1,795 (4.8%)\n        Selangor\n11,024 (30%)\n        Terengganu\n905 (2.4%)\n        W.P. Kuala Lumpur\n2,861 (7.7%)\n        W.P. Labuan\n159 (0.4%)\n        W.P. Putrajaya\n29 (<0.1%)\n    male\n21,369 (58%)\n    malaysian\n33,118 (89%)\n    bid\n7,906 (21%)\n  \n  \n  \n    \n      1 Median (IQR); n (%)\n    \n  \n\n\n\n\n\n\nAdjustments\nby =\nYou can stratify your table by a column (e.g. by outcome), creating a 2-way table.\nstatistic =\nUse an equations to specify which statistics to show and how to display them. There are two sides to the equation, separated by a tilde ~. On the right side, in quotes, is the statistical display desired, and on the left are the columns to which that display will apply.\n\nc19_df %>% \n  select(age) %>%               # keep only columns of interest \n  tbl_summary(                  # create summary table\n    statistic = age ~ \"{mean} ({sd})\") # print mean of age\n\n\n\n\n\n  \n  \n    \n      Characteristic\n      N = 37,1521\n    \n  \n  \n    age\n63 (17)\n  \n  \n  \n    \n      1 Mean (SD)\n    \n  \n\n\n\n\ndigits =\nAdjust the digits and rounding. Optionally, this can be specified to be for continuous columns only (as below).\nlabel =\nAdjust how the column name should be displayed. Provide the column name and its desired label separated by a tilde. The default is the column name.\nmissing_text =\nAdjust how missing values are displayed. The default is “Unknown”.\ntype =\nThis is used to adjust how many levels of the statistics are shown. The syntax is similar to statistic = in that you provide an equation with columns on the left and a value on the right. Two common scenarios include:\n\ntype = all_categorical() ~ \"categorical\" Forces dichotomous columns (e.g. fever yes/no) to show all levels instead of only the “yes” row\n\ntype = all_continuous() ~ \"continuous2\" Allows multi-line statistics per variable, as shown in a later section\n\n\nc19_df %>% \n  mutate(across(contains(\"date\"), ~as.Date(., format = \"%Y-%m-%d\")), #change character to dates\\ fromat\n         days_delay=date_announced-date,\n         days_admitted=date-date_positive,\n         vaccinated=ifelse(is.na(date_dose2), \"unvaccinated\", \"vaccinated\")) %>%\n  select(age, male, malaysian, bid, vaccinated,\n         comorb, days_delay, days_admitted) %>% # keep only columns of interest\n  tbl_summary(     \n    by = malaysian,                                               # stratify entire table by outcome\n    statistic = list(all_continuous() ~ \"{mean} ({sd})\",        # stats and format for continuous columns\n                     all_categorical() ~ \"{n} / {N} ({p}%)\"),   # stats and format for categorical columns\n    digits = all_continuous() ~ 1,                              # rounding for continuous columns\n    type   = all_categorical() ~ \"categorical\",                 # force all categorical levels to display\n    label  = list(                                              # display labels for column names\n      malaysian      ~ \"Nationality\",                           \n      age            ~ \"Age (years)\",\n      male           ~ \"Gender\",\n      bid            ~ \"Brought-in-dead\",\n      comorb         ~ \"Comorbids\",\n      vaccinated     ~ \"Vaccine status\",\n      days_admitted  ~ \"Duration between diagnosis and death (days) \",\n      days_delay     ~ \"Duration between death and announcement (days)\"),\n    missing_text = \"NA\"                                    # how missing values should display\n  )\n\n\n\n\n\n  \n  \n    \n      Characteristic\n      0, N = 4,0341\n      1, N = 33,1181\n    \n  \n  \n    Age (years)\n49.5 (14.3)\n64.3 (16.1)\n    Gender\n\n\n        0\n1,649 / 4,034 (41%)\n14,134 / 33,118 (43%)\n        1\n2,385 / 4,034 (59%)\n18,984 / 33,118 (57%)\n    Brought-in-dead\n\n\n        0\n1,958 / 4,034 (49%)\n27,288 / 33,118 (82%)\n        1\n2,076 / 4,034 (51%)\n5,830 / 33,118 (18%)\n    Vaccine status\n\n\n        unvaccinated\n3,808 / 4,034 (94%)\n24,226 / 33,118 (73%)\n        vaccinated\n226 / 4,034 (5.6%)\n8,892 / 33,118 (27%)\n    Comorbids\n\n\n        0\n2,175 / 4,034 (54%)\n5,717 / 33,118 (17%)\n        1\n1,859 / 4,034 (46%)\n27,401 / 33,118 (83%)\n    Duration between death and announcement (days)\n15.0 (19.4)\n8.9 (18.2)\n    Duration between diagnosis and death (days) \n4.1 (14.6)\n6.6 (10.0)\n  \n  \n  \n    \n      1 Mean (SD); n / N (%)\n    \n  \n\n\n\n\n\n\nMulti-line stats for continuous variables\nIf you want to print multiple lines of statistics for continuous variables, you can indicate this by setting the type = to “continuous2”. You can combine all of the previously shown elements in one table by choosing which statistics you want to show. To do this you need to tell the function that you want to get a table back by entering the type as “continuous2”. The number of missing values is shown as “Unknown”.\n\nc19_df %>%\n  mutate(across(contains(\"date\"), ~as.Date(., format = \"%Y-%m-%d\")), #change character to dates\\ fromat\n         days_delay=date_announced-date,\n         days_admitted=date-date_positive) %>%\n  select(age, days_delay, days_admitted) %>% # keep only columns of interest\n  tbl_summary(                               # create summary table\n    type = all_continuous() ~ \"continuous2\", # indicate that you want to print multiple statistics \n    statistic = all_continuous() ~ c(\n      \"{mean} ({sd})\",                       # line 1: mean and SD\n      \"{median} ({p25}, {p75})\",             # line 2: median and IQR\n      \"{min}, {max}\")                        # line 3: min and max\n    )\n\n\n\n\n\n  \n  \n    \n      Characteristic\n      N = 37,152\n    \n  \n  \n    age\n\n        Mean (SD)\n63 (17)\n        Median (IQR)\n64 (51, 75)\n        Range\n0, 130\n    days_delay\n\n        Mean (SD)\n10 (18)\n        Median (IQR)\n3 (2, 7)\n        Range\n0, 396\n    days_admitted\n\n        Mean (SD)\n6 (11)\n        Median (IQR)\n4 (0, 9)\n        Range\n0, 724\n  \n  \n  \n\n\n\n\n\n\n\nrstatix() for inferential statistics\n\n\n\n\n\nInferential statistics is a set of statistical procedures that allows us to draw conclusions about an entire population from a representative sample. The importance of inferential statistics lies in its ability to:\n\nGeneralize about a population: Inferential statistics enables researchers to make predictions or inferences about a population based on the observations made in a sample.\nTest hypotheses: With inferential statistics, researchers can test a hypothesis to determine its statistical significance.\nStudy relationships: It allows researchers to examine the relationships between different variables in a sample and to generalize these relationships to the broader population.\n\nWe will not focus on the mathematics behind inferential statistics but more so the impementation within R. Nontheless, here is a quick summary of commonly used inferential statistical tests and when they are used:\n\nT-tests (One-sample, Independent Two-sample, and Paired): These are used when we want to compare the means of one or two groups. For example, comparing the average height of men and women.\nAnalysis of Variance (ANOVA): ANOVA is used when comparing the means of more than two groups. For example, comparing the average income of people in three different cities.\nChi-square test: The chi-square test is used to determine if there is a significant association between two categorical variables. For example, examining the relationship between gender and voting behavior.\nCorrelation and Regression: Correlation is used to measure the strength and direction of the linear relationship between two variables. Regression is used to predict the value of one variable based on the value of another.\n\nEach test has assumptions that need to be satisfied for the results to be accurate, so it’s essential to choose the right test for the data and research question at hand.\nWhile it is possible to run these tests in base() R, we will skip that in this course since our grounding has all been carried out within the tidyverse(). If you wish to study inferential statistics using base () R you can have a look at this.\nFor the purposes of this course we shall take a deeper look at the rstatix package:\n\nT-test\nUse a formula syntax to specify the numeric and categorical columns for a two sample t-test:\n\nc19_df %>% \n  t_test(age ~ male)\n\n# A tibble: 1 × 8\n  .y.   group1 group2    n1    n2 statistic     df        p\n* <chr> <chr>  <chr>  <int> <int>     <dbl>  <dbl>    <dbl>\n1 age   0      1      15783 21369      9.05 32644. 1.55e-19\n\n\nOr a one-sample t-test\n\nc19_df %>% \n  t_test(age ~ 1, mu = 60)\n\n# A tibble: 1 × 7\n  .y.   group1 group2         n statistic    df         p\n* <chr> <chr>  <chr>      <int>     <dbl> <dbl>     <dbl>\n1 age   1      null model 37152      30.8 37151 2.73e-206\n\n\nOr one sample t-tests by group\n\nc19_df %>% \n  group_by(male) %>% \n  t_test(age ~ 1, mu = 60)\n\n# A tibble: 2 × 8\n   male .y.   group1 group2         n statistic    df         p\n* <int> <chr> <chr>  <chr>      <int>     <dbl> <dbl>     <dbl>\n1     0 age   1      null model 15783      26.0 15782 2.3 e-146\n2     1 age   1      null model 21369      18.0 21368 6.59e- 72\n\n\n\n\nShapiro-Wilk test\nNote: Sample size must be between 3-5000\n\nc19_df %>% \n  head(500) %>%            # first 500 rows of case linelist, for example only\n  shapiro_test(age)\n\n# A tibble: 1 × 3\n  variable statistic             p\n  <chr>        <dbl>         <dbl>\n1 age          0.967 0.00000000413\n\n\n\n\nWilcoxon rank sum test\n\nc19_df %>% \n  wilcox_test(age ~ malaysian)\n\n# A tibble: 1 × 7\n  .y.   group1 group2    n1    n2 statistic     p\n* <chr> <chr>  <chr>  <int> <int>     <dbl> <dbl>\n1 age   0      1       4034 33118 31201584.     0\n\n\n\n\nKruskal-Wallis test\nAlso known as the Mann-Whitney U test.\n\nc19_df %>% \n  kruskal_test(age ~ state)\n\n# A tibble: 1 × 6\n  .y.       n statistic    df         p method        \n* <chr> <int>     <dbl> <int>     <dbl> <chr>         \n1 age   37152     1367.    15 2.03e-282 Kruskal-Wallis\n\n\n\n\nChi-squared test\nThe chi-square test function accepts a table, so first we create a cross-tabulation. There are many ways to create a cross-tabulation but here we use tabyl() from janitor and remove the left-most column of value labels before passing to chisq_test().\n\nc19_df %>% \n  tabyl(malaysian, bid) %>% \n  select(-1) %>% \n  chisq_test()\n\n# A tibble: 1 × 6\n      n statistic     p    df method          p.signif\n* <dbl>     <dbl> <dbl> <int> <chr>           <chr>   \n1 37152     2459.     0     1 Chi-square test ****    \n\n\n\n\n\ngtsummary() package for Inferential statistics\nUse gtsummary if you are looking to add the results of a statistical test to a pretty table that was created with this package. Performing statistical tests of comparison with tbl_summary is done by adding the add_p function to a table and specifying which test to use. It is possible to get p-values corrected for multiple testing by using the add_q function. Run ?tbl_summary for details.\n\n\n\n\n\n\nT-tests\nCompare the difference in means for a continuous variable in two groups. For example, compare the mean age by patient outcome.\n\nc19_df %>% \n  select(age, malaysian) %>%                 # keep variables of interest\n  tbl_summary(                               # produce summary table\n    statistic = age ~ \"{mean} ({sd})\",       # specify what statistics to show\n    by = malaysian) %>%                      # specify the grouping variable\n  add_p(age ~ \"t.test\")                      # specify what tests to perform\n\n\n\n\n\n  \n  \n    \n      Characteristic\n      0, N = 4,0341\n      1, N = 33,1181\n      p-value2\n    \n  \n  \n    age\n49 (14)\n64 (16)\n<0.001\n  \n  \n  \n    \n      1 Mean (SD)\n    \n    \n      2 Welch Two Sample t-test\n    \n  \n\n\n\n\n\n\nWilcoxon rank sum test\nCompare the distribution of a continuous variable in two groups. The default is to use the Wilcoxon rank sum test and the median (IQR) when comparing two groups. However for non-normally distributed data or comparing multiple groups, the Kruskal-wallis test is more appropriate.\n\nc19_df %>% \n  select(age, malaysian) %>%                     # keep variables of interest\n  tbl_summary(                                   # produce summary table\n    statistic = age ~ \"{median} ({p25}, {p75})\", # specify what statistic to show (this is default so could remove)\n    by = malaysian) %>%                          # specify the grouping variable\n  add_p(age ~ \"wilcox.test\")                     # specify what test to perform (default so could leave brackets empty)\n\n\n\n\n\n  \n  \n    \n      Characteristic\n      0, N = 4,0341\n      1, N = 33,1181\n      p-value2\n    \n  \n  \n    age\n48 (41, 56)\n66 (54, 76)\n<0.001\n  \n  \n  \n    \n      1 Median (IQR)\n    \n    \n      2 Wilcoxon rank sum test\n    \n  \n\n\n\n\n\n\nKruskal-wallis test\nCompare the distribution of a continuous variable in two or more groups, regardless of whether the data is normally distributed.\n\nc19_df %>% \n  select(age, state) %>%                         # keep variables of interest\n  tbl_summary(                                   # produce summary table\n    statistic = age ~ \"{median} ({p25}, {p75})\", # specify what statistic to show (default, so could remove)\n    by = state) %>%                              # specify the grouping variable\n  add_p(age ~ \"kruskal.test\")                    # specify what test to perform\n\n\n\n\n\n  \n  \n    \n      Characteristic\n      Johor, N = 4,7401\n      Kedah, N = 2,7561\n      Kelantan, N = 1,4281\n      Melaka, N = 1,2131\n      Negeri Sembilan, N = 1,5461\n      Pahang, N = 1,0371\n      Perak, N = 2,1641\n      Perlis, N = 1991\n      Pulau Pinang, N = 2,0851\n      Sabah, N = 3,2111\n      Sarawak, N = 1,7951\n      Selangor, N = 11,0241\n      Terengganu, N = 9051\n      W.P. Kuala Lumpur, N = 2,8611\n      W.P. Labuan, N = 1591\n      W.P. Putrajaya, N = 291\n      p-value2\n    \n  \n  \n    age\n62 (49, 73)\n64 (52, 76)\n68 (58, 77)\n64 (50, 75)\n66 (55, 76)\n64 (53, 75)\n70 (58, 79)\n71 (60, 81)\n69 (55, 79)\n67 (56, 78)\n71 (59, 79)\n60 (48, 71)\n67 (57, 77)\n63 (50, 74)\n60 (48, 72)\n68 (60, 73)\n<0.001\n  \n  \n  \n    \n      1 Median (IQR)\n    \n    \n      2 Kruskal-Wallis rank sum test\n    \n  \n\n\n\n\n\n\nChi-squared test\nCompare the proportions of a categorical variable in two groups. The default statistical test for add_p() when applied to a categorical variable is to perform a chi-squared test of independence with continuity correction, but if any expected call count is below 5 then a Fisher’s exact test is used.\n\nc19_df %>% \n  select(malaysian, bid) %>% # keep variables of interest\n  tbl_summary(by = bid) %>%  # produce summary table and specify grouping variable\n  add_p()                    # specify what test to perform\n\n\n\n\n\n  \n  \n    \n      Characteristic\n      0, N = 29,2461\n      1, N = 7,9061\n      p-value2\n    \n  \n  \n    malaysian\n27,288 (93%)\n5,830 (74%)\n<0.001\n  \n  \n  \n    \n      1 n (%)\n    \n    \n      2 Pearson's Chi-squared test\n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\nCorrelations in R\nCorrelation between numeric variables can be investigated using the tidyverse\ncorrr package. It allows you to compute correlations using Pearson, Kendall tau or Spearman rho. The package creates a table and also has a function to automatically plot the values.\n\ncorrelation_tab <- c19_df %>%\n  mutate(across(contains(\"date\"), ~as.Date(., format = \"%Y-%m-%d\")), #change character to dates\\ fromat\n         days_delay=as.numeric(date_announced-date),\n         days_admitted=as.numeric(date-date_positive)) %>%\n  select(age, days_delay, days_admitted) %>%                         # keep only columns of interest\n  correlate()                                        # create correlation table (using default pearson)\n\nCorrelation computed with\n• Method: 'pearson'\n• Missing treated using: 'pairwise.complete.obs'\n\ncorrelation_tab                                                      # print\n\n# A tibble: 3 × 4\n  term              age days_delay days_admitted\n  <chr>           <dbl>      <dbl>         <dbl>\n1 age           NA         -0.0998       -0.0307\n2 days_delay    -0.0998    NA            -0.0531\n3 days_admitted -0.0307    -0.0531       NA     \n\n\nPlot a scatteplot of correlations\n\n## plot correlations \nrplot(correlation_tab)\n\n\n\n\nFinally you can create a nifty little heatmap. You can calculate a correlation data frame using the correlate() function from corrr, reshape it into a long format with melt(), and then create a heatmap with ggplot2:\n\ncorrelation_tab %>% autoplot(triangular=\"full\") +\n  geom_text(aes(label=round(r, digits=2)), size=4)+\n  theme_minimal(16)\n\n\n\n\n\n\nAcknowledgements\nMaterial for this lecture was borrowed and adopted from\n\nThe Epidemiologist R Handbook\nhttps://rafalab.github.io/dsbook"
  },
  {
    "objectID": "inferential_stats_solutions.html",
    "href": "inferential_stats_solutions.html",
    "title": "Practical Statistics 3: Powering up! Descriptive and Inferential Statistics",
    "section": "",
    "text": "Task 1: Descriptive statistics using tidyverse\nQuestion: Compute the summary statistics (count, mean, standard deviation, minimum, and maximum) of age using tidyverse functions.\nSteps:\n\nInstall and load the tidyverse package.\nFilter the dataset to remove missing values in the “age” column (Note there are no missing values in the dataset- the task is simply meant to simulate the code that would be required if there were).\nUse the summary functions from dplyr to compute the required summary statistics. In this case- count, mean, standard deviation, minimum, and maximum\n\nSolution:\n\n# Step 1\n#install.packages(\"tidyverse\")\nlibrary(tidyverse)\n\n# Step 2 & 3\nsummary_age <- c19_df %>% filter(!is.na(age)) %>% \n  summarise(\n  count = n(),\n  mean = mean(age),\n  sd = sd(age),\n  min = min(age),\n  max = max(age)\n)\nsummary_age\n\n  count     mean       sd min max\n1 37152 62.65464 16.58926   0 130\n\n\n\n\nTask 2: Descriptive statistics using gtsummary\nQuestion: Create a descriptive statistics table for age, male, bid, and malaysian variables using gtsummary.\nSteps:\n\nInstall and load the gtsummary package.\nCreate a subset of the data with the selected variables (Note: Select any five variables).\nUse the tbl_summary() function to compute and display the descriptive statistics.\nStratify by any other selected variable.\n\nSolution:\n\n# Step 1\n#install.packages(\"gtsummary\")\nlibrary(gtsummary)\n\n# Step 2, 3 & 4\ndf_subset <- c19_df %>% \n  select(age, male, bid, malaysian) %>% \n  tbl_summary(by = malaysian)\n\n\n\nTask 3: Inferential statistics using rstatix\nQuestion: Test if there is a significant difference in age between males and females using the t-test.\nSteps:\n\nInstall and load the rstatix package.\nFilter the dataset to remove missing values in the “age” and “male” columns.\nRecode the “male” variable to factor.\nConduct a t-test to compare the means.\n\nSolution:\n\n# Step 1\n#install.packages(\"rstatix\")\nlibrary(rstatix)\n\n# Step 2\nc19_df <- c19_df %>% filter(!is.na(age), !is.na(male))\n\n# Step 3\nc19_df$male <- factor(c19_df$male, levels = c(0, 1), labels = c(\"Female\", \"Male\"))\n\n# Step 4\nc19_df %>% t_test(age ~ male)\n\n# A tibble: 1 × 8\n  .y.   group1 group2    n1    n2 statistic     df        p\n* <chr> <chr>  <chr>  <int> <int>     <dbl>  <dbl>    <dbl>\n1 age   Female Male   15783 21369      9.05 32644. 1.55e-19\n\n\n\n\nTask 4: Inferential statistics using gtsummary\nQuestion: Test if there is a significant difference in age between Malaysians and non-Malaysians using the t-test, and present the results in a table using gtsummary.\nSteps:\n\nRecode the “malaysian” variable to factor (Tip: Use the factor function).\nUse the tbl_summary() function to present the results.\n\nSolution:\n\n# Step 1\nc19_df$malaysian <- factor(c19_df$malaysian, levels = c(0, 1), labels = c(\"Non-Malaysian\", \"Malaysian\"))\n\n# Step 2\nt_test_result <- c19_df %>% \n  select(age, malaysian) %>%                 # keep variables of interest\n  tbl_summary(                               # produce summary table\n    statistic = age ~ \"{mean} ({sd})\",       # specify what statistics to show\n    by = malaysian) %>%                      # specify the grouping variable\n  add_p(age ~ \"t.test\") \nt_test_result\n\n\n\n\n\n  \n  \n    \n      Characteristic\n      Non-Malaysian, N = 4,0341\n      Malaysian, N = 33,1181\n      p-value2\n    \n  \n  \n    age\n49 (14)\n64 (16)\n<0.001\n  \n  \n  \n    \n      1 Mean (SD)\n    \n    \n      2 Welch Two Sample t-test\n    \n  \n\n\n\n\n\n\nTask 5: Correlations using corrr\nQuestion: Compute the correlation between age, male, bid, and malaysian variables, and represent it in a correlation plot (Note: The selection of categorical variables is by design- just to practice the selection and presentation)\nSteps:\n\nInstall and load the corrr package.\nCreate a subset of the data with the selected variables.\nCompute the correlation matrix (Note: Try ?network_plot and see how this can be used)\n\n\n# Step 1\n#install.packages(\"corrr\")\nlibrary(corrr)\n\n# Step 2\ndf_subset <- c19_df %>% select(age, male, bid, malaysian)\n\n# Step 3\ncorrelation_matrix <- df_subset %>% correlate()\n\nNon-numeric variables removed from input: `male`, and `malaysian`\nCorrelation computed with\n• Method: 'pearson'\n• Missing treated using: 'pairwise.complete.obs'\n\n# Step 4\ncorrelation_matrix %>% network_plot()\n\n\n\n\n\n\n\n\n\nThis would be the outcome if anything was highly correlated in our data."
  },
  {
    "objectID": "inferential_stats_tutorial.html",
    "href": "inferential_stats_tutorial.html",
    "title": "Practical Statistics 3: Powering up! Descriptive and Inferential Statistics",
    "section": "",
    "text": "Task 2: Descriptive statistics using gtsummary\nQuestion: Create a descriptive statistics table for age, male, bid, and malaysian variables using gtsummary.\nSteps:\n\nInstall and load the gtsummary package.\nCreate a subset of the data with the selected variables (Note: Select any five variables).\nUse the tbl_summary() function to compute and display the descriptive statistics.\nStratify by any other selected variable.\n\n\n\nTask 3: Inferential statistics using rstatix\nQuestion: Test if there is a significant difference in age between males and females using the t-test.\nSteps:\n\nInstall and load the rstatix package.\nFilter the dataset to remove missing values in the “age” and “male” columns.\nRecode the “male” variable to factor.\nConduct a t-test to compare the means.\n\n\n\nTask 4: Inferential statistics using gtsummary\nQuestion: Test if there is a significant difference in age between Malaysians and non-Malaysians using the t-test, and present the results in a table using gtsummary.\nSteps:\n\nRecode the “malaysian” variable to factor (Tip: Use the factor function).\nUse the tbl_summary() function to present the results.\n\nSolution:\n\n\nTask 5: Correlations using corrr\nQuestion: Compute the correlation between age, male, bid, and malaysian variables, and represent it in a correlation plot (Note: The selection of categorical variables is by design- just to practice the selection and presentation)\nSteps:\n\nInstall and load the corrr package.\nCreate a subset of the data with the selected variables.\nCompute the correlation matrix (Note: Try ?network_plot and see how this can be used)\n\n\n\n\n\n\nThis would be the outcome if anything was highly correlated in our data."
  },
  {
    "objectID": "installation.html#topics-covered",
    "href": "installation.html#topics-covered",
    "title": "Setup R in your System",
    "section": "Topics Covered",
    "text": "Topics Covered\n1. Installing R\n2. Installing RStudio\n3. Installing the tidyverse package\n4. Using R Tools for package installation and updates"
  },
  {
    "objectID": "installation.html#what-is-r",
    "href": "installation.html#what-is-r",
    "title": "Setup R in your System",
    "section": "What is R?",
    "text": "What is R?\nR is a programming language and software environment for statistical computing and graphics."
  },
  {
    "objectID": "installation.html#installing-r---step-1",
    "href": "installation.html#installing-r---step-1",
    "title": "Setup R in your System",
    "section": "Installing R - Step 1",
    "text": "Installing R - Step 1\n\nVisit the Comprehensive R Archive Network (CRAN) at https://cran.r-project.org/."
  },
  {
    "objectID": "installation.html#installing-r---step-2",
    "href": "installation.html#installing-r---step-2",
    "title": "Setup R in your System",
    "section": "Installing R - Step 2",
    "text": "Installing R - Step 2\n\nChoose your operating system (Windows, OS X, Linux).\nClick on “base” or the latest version.\nDownload and install it."
  },
  {
    "objectID": "installation.html#what-is-rstudio",
    "href": "installation.html#what-is-rstudio",
    "title": "Setup R in your System",
    "section": "What is RStudio?",
    "text": "What is RStudio?\nRStudio is an integrated development environment (IDE) for R. It makes it easier to write and manage your R code."
  },
  {
    "objectID": "installation.html#installing-rstudio---step-1",
    "href": "installation.html#installing-rstudio---step-1",
    "title": "Setup R in your System",
    "section": "Installing RStudio - Step 1",
    "text": "Installing RStudio - Step 1\nVisit https://www.rstudio.com/products/rstudio/download/ and click on the “Download” button under RStudio Desktop."
  },
  {
    "objectID": "installation.html#installing-rstudio---step-2",
    "href": "installation.html#installing-rstudio---step-2",
    "title": "Setup R in your System",
    "section": "Installing RStudio - Step 2",
    "text": "Installing RStudio - Step 2\n\nChoose your operating system.\nDownload and install it."
  },
  {
    "objectID": "installation.html#what-is-tidyverse",
    "href": "installation.html#what-is-tidyverse",
    "title": "Setup R in your System",
    "section": "What is Tidyverse?",
    "text": "What is Tidyverse?\nTidyverse is a collection of R packages designed for data science. All packages share an underlying design philosophy and grammar."
  },
  {
    "objectID": "installation.html#installing-the-tidyverse-package",
    "href": "installation.html#installing-the-tidyverse-package",
    "title": "Setup R in your System",
    "section": "Installing the Tidyverse Package",
    "text": "Installing the Tidyverse Package\nTo install the tidyverse package, run the following command in the RStudio console:\n\ninstall.packages(\"tidyverse\", repos = \"http://cran.us.r-project.org\")\n\npackage 'tidyverse' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\sueth\\AppData\\Local\\Temp\\RtmpwR45rs\\downloaded_packages"
  },
  {
    "objectID": "installation.html#loading-the-tidyverse-package",
    "href": "installation.html#loading-the-tidyverse-package",
    "title": "Setup R in your System",
    "section": "Loading the Tidyverse Package",
    "text": "Loading the Tidyverse Package\nAfter installation, you can load the tidyverse package with:\n\nlibrary(tidyverse)"
  },
  {
    "objectID": "installation.html#introduction-to-r-tools",
    "href": "installation.html#introduction-to-r-tools",
    "title": "Setup R in your System",
    "section": "Introduction to R Tools",
    "text": "Introduction to R Tools\nR Tools is a collection of tools that integrates nicely with R and RStudio. It’s essential for developing packages and includes tools like gcc and make.\nPlease note that as of 2021, RTools has been superseded by RTools40 for R versions 4.0.0 and onwards. The install process is similar but you should consult the most up-to-date resources."
  },
  {
    "objectID": "installation.html#why-rtools",
    "href": "installation.html#why-rtools",
    "title": "Setup R in your System",
    "section": "Why RTools?",
    "text": "Why RTools?\n- Needed if you plan to create your own R packages\n- Useful if you want to install a development version of a package hosted on GitHub"
  },
  {
    "objectID": "installation.html#installing-rtools---step-1",
    "href": "installation.html#installing-rtools---step-1",
    "title": "Setup R in your System",
    "section": "Installing RTools - Step 1",
    "text": "Installing RTools - Step 1\nVisit CRAN’s RTools download page at https://cran.r-project.org/bin/windows/Rtools/."
  },
  {
    "objectID": "installation.html#installing-rtools---step-2",
    "href": "installation.html#installing-rtools---step-2",
    "title": "Setup R in your System",
    "section": "Installing RTools - Step 2",
    "text": "Installing RTools - Step 2\n\nDownload the appropriate RTools installer for your version of R. Check your R version by running `R.version.string` in your R console.\nRun the installer and follow the instructions. Make sure to check the box that says “Edit the system PATH”.\nRestart RStudio so the changes take effect."
  },
  {
    "objectID": "installation.html#verifying-rtools-installation",
    "href": "installation.html#verifying-rtools-installation",
    "title": "Setup R in your System",
    "section": "Verifying RTools Installation",
    "text": "Verifying RTools Installation\nIn RStudio, run the following command:\n\nSys.which(\"make\")\n\n                                      make \n\"C:\\\\RBuildTools\\\\4.2\\\\usr\\\\bin\\\\make.exe\" \n\n\nIf RTools was installed correctly, it should show the path to the `make` executable."
  },
  {
    "objectID": "installation.html#using-rtools",
    "href": "installation.html#using-rtools",
    "title": "Setup R in your System",
    "section": "Using RTools",
    "text": "Using RTools\nNow, you can use the `install.packages()` function to install packages from source or the `devtools::install_github()` function to install packages from GitHub.\n\n# install.packages(\"package_name\", type = \"source\")\n\n# devtools::install_github(\"username/package_name\")"
  },
  {
    "objectID": "introduction_R.html",
    "href": "introduction_R.html",
    "title": "Introduction to R",
    "section": "",
    "text": "Welcome to Statistical Computing in R! (Beginner-Intermediate) organised by the Sector for Biostatistics and Data Respository, National Instititues of Health."
  },
  {
    "objectID": "introduction_R.html#speakers",
    "href": "introduction_R.html#speakers",
    "title": "Introduction to R",
    "section": "Speakers",
    "text": "Speakers\n\n\n\n\n\nVivek Jason\nJason is a gazetting Public Health Physician passionate about epidemiology, infectious diseases and data science. He spends his time between coding, playing with his toddler and pondering the fate of the universe.\n\n\n\n\n\nAng Swee Hung\nSwee Hung is a training Public Health Physician that works heavily in the fields of non-communicable disease epidemiology. Renowned for her calmness under pressure- Swee Hung also enjoys the serenity of long drives.\n\n\n\n\n\nEvi Diana\nEvi is a statistician with vast expertise in complex sample analysis and clustering. The only person whose math you should trust in this workshop- Evi always has a smile on her face.\n\nSchedule\n\n\n\n\n\n\n\n\nDate\nTime\nTopic\n\n\n\n\n10.7.2022 (Monday)\n08.30 am - 09.00 am\nRegistration\n\n\n\n9.00 am - 10.00 am\nIntroduction to R Software\n\n\n\n10.00 am - 12.30 pm\nData wrangling\n\n\n\n12.30 pm - 02.00 pm\nBreak\n\n\n\n02.00 pm - 04.30 pm\nData Visualization\n\n\n11.7.2022 (Tuesday)\n08.00 am – 08.30 am\nRegistration\n\n\n\n08.30 am - 11.30 am\nHypothesis testing\n\n\n\n1.00 pm - 02.15 pm\nBreak\n\n\n\n02.15 pm - 04.30 pm\nIntroduction to Regression\n\n\n\n04.30 pm - 05.00 pm\nQ&A\n\n\n\n\n\nWhat will we learn in the next hour?\n\nSome backround on R\nUnderstanding R and RStudio\nGrammar of R\nTaking the next step\n\n\n\nWhat is…\n\n\n\n\n\n\n\na software package for statistical computing and graphics\na collection of 18,636packages (as of September 2020)!\na (not ideal) programming language\na work environment, widely used, POWERFUL!\n\n\n\nWhy use R\n\nIt’s free!\nIt runs on a variety of platforms including Windows, Unix and MacOS.\nIt provides an unparalleled platform for programming new statistical methods in an easy and straightforward manner.\nIt contains advanced statistical routines not yet available in other packages.\nIt has state-of-the-art graphics capabilities\nThe next step for open-science initiatives chief being reproducibility\n\n\n\n\n\n\n\nA note on reproducibility\n\n\n\n\nReplication, whereby scientific questions are examined and verified independently by different scientists, is the gold standard for scientific validity.\nReplication can be difficult and often there are no resources to independently replicate a study.\nReproducibility, whereby data and code are re-analyzed by independent scientists to obtain the same results of the original investigator, is a reasonable minimum standard when replication is not possible.\n\n\n\n\n\nReproducibility and Literate Programming\nOne basic idea to make writing reproducible reports easier is what’s known as literate statistical programming (or sometimes called literate statistical practice). This comes from the idea of literate programming in the area of writing computer programs.\nThe idea is to think of a report or a publication as a stream of text and code.\n\nThe text is readable by people and the code is readable by computers.\nThe analysis is described in a series of text and code chunks.\nEach kind of code chunk will do something like load some data or compute some results.\nEach text chunk will relay something in a human readable language.\n\nThere might also be presentation code that formats tables and figures and there’s article text that explains what’s going on around all this code. This stream of text and code is a literate statistical program or a literate statistical analysis.\n\n\nCRAN:Comprehensive R Archive Network\nAt a higher level one “limitation” of R is that its functionality is based on consumer demand and (voluntary) user contributions. If no one feels like implementing your favorite method, then it’s your job to implement it (or you need to pay someone to do it). The capabilities of the R system generally reflect the interests of the R user community. As the community has ballooned in size over the past 10 years, the capabilities have similarly increased. This can be seen in the exponential increase in packages on CRAN\n\n\n\n\n\n\n\nHistory time\n\nS was developed at Bell Labs, starting in the 1970s\nR was created in the 1990s by Ross Ihaka and Robert Gentleman\nR was based on S, with code written in C\nS largely was used to make good graphs – not an easy thing in 1975. R, like S, is quite good for graphing\n\n\n\n\nDesign of the R System\nThe primary R system is available from the Comprehensive R Archive Network, also known as CRAN. CRAN also hosts many add-on packages that can be used to extend the functionality of R.\nThe R system is divided into 2 conceptual parts:\n\nThe “base” R system that you download from CRAN:\n\n\nLinux\nWindows\nMac\n\n\nEverything else.\n\nR functionality is divided into a number of packages.\n\nThe “base” R system contains, among other things, the base package which is required to run R and contains the most fundamental functions.\nThe other packages contained in the “base” system include utils, stats, datasets, graphics, grDevices, grid, methods, tools, parallel, compiler, splines, tcltk, stats4.\nThere are also “Recommended” packages: boot, class, cluster, codetools, foreign, KernSmooth, lattice, mgcv, nlme, rpart, survival, MASS, spatial, nnet, Matrix.\n\nWhen you download a fresh installation of R from CRAN, you get all of the above, which represents a substantial amount of functionality. However, there are many other packages available:\n\nThere are over 10,000 packages on CRAN that have been developed by users and programmers around the world.\nThere are also many packages associated with the Bioconductor project.\nPeople often make packages available on their personal websites; there is no reliable way to keep track of how many packages are available in this fashion.\n\n\n\nAt its core R is a programming language\n\nConcepts such as loops and functions speed up and simplify analytic processes\nIf you want R to be (relatively) fast, take advantage of vector operations; e.g., use the replicate command (rather than a loop) or the apply function.\noptimising computation is critical to newer processes i.e. big data\n\n\n\nR is object oriented\n\ne.g., MyModel <- lm(wt ~ ht, data = mydata)\nthen hist(MyModel$residuals)\nNote that lm(wt ~ ht*age + log(bp), data = mydata) regresses wt on ht, age, the ht-by-age interaction, and log(bp)\nThere is no need to create the interaction or the log(bp) variable outside of the lm() command\nanother e.g.\nmod1 <- lm(wt ~ ht*age + log(bp), data = mydata)\nmod2 <- lm(wt ~ ht + log(bp), data = mydata)\nanova(mod2, mod1) gives a nested/ interaction F-test\n\n\n\nLimitations\n\nfresh non-coders may find it difficult at first , the curve is steep especially if you have no background\nhundreds of packages mean learning 100s of different things and styles - analysis is much more transient\nSPSS, STATA use a much more ordered approach - fresh non-coders may find it difficult at first\ngenerally a intepreted language (vs compiled), this makes certain operations clunky and slow like looping\n\n\nNonetheless The R paradigm is different- its uses a more iterative approach and as such analysis is more flexible, makes a more in depth inquiry of data Mastery is key to tapping the potential of data science in real-world and research settings The first key to mastery of R is….\nUNINSTALL SPSS AS.. QUICKLY.. AS.. YOU.. CAN!!\n\n\n\n\n\n\n\nRstudio\n\nAn Integrated Development Environment (IDE) for R\nA gift, from J.J. Allaire (Macalester College, ’91) to the world\nAn easy (easier) way to use R\nAvailable as a desktop product or, run off a server or cloud\nRecently renamed as Posit- to include Python, VS and Quatro\nFree to a degree!\n\n\n\n\n\n\n\n\n\nRStudio environment\n\n\n\n\n\n\n\nSetting a working directory\nCheck you working directory by\n\n\n\nYou can then set your working directory like this\n\n\n\n\n\n\n\n\n\nSetting a work directory like this is called an absolute path and in statistical computing is a frowned upon practice as it locks directories to you system only. Instead we should utilise relative paths.\n\n\n\n\n\n\nA relative path should look like this\n\n\n\nThere are even better practices for sustainability and reproducibility such but we wont cover those practices here. You can find more information in this post\n\n\nReading data into R\nThis section demonstrates the fundamental functions required to read and write data in R.\nIn base R, there are key functions for reading data:\n\nread.table() & read.csv(): used for reading tabular data\nreadLines(): used for reading lines from a text file\n\nCorresponding functions exist for writing data:\n\nwrite.table(): used to write tabular data to text files or connections, such as CSV\nwriteLines(): used to write character data line-by-line to a file or connection\n\nLet’s attempt to read data into R using the read.csv() function.\n\ndf <- read.csv(\"data/yourfilename.csv\")#this is just an example\n\nYou can even pull a csv straight from the web\n\ndf <- read.csv(\"https://raw.githubusercontent.com/MoH-Malaysia/data-darah-public/main/newdonors_state.csv\")\n\nYou can export he above csv to you computer by\n\n\n\nTo extract a specific column, we can use the $ symbol:\n\ndf$hospital\n\nNULL\n\n\nAlmost all imaginable formats can be imported/ exported into R. For a more in depth explanation you can have a look at this book chapter.\n\n\nBase R Grammar\n\nResults of calculations can be stored in objects using the assignment operators: An arrow (<-) formed by a smaller than character and a hyphen without a space! The equal character (=).\nObject names cannot contain `strange’ symbols like !, +, -, #.\nA dot (.) and an underscore ( ) are allowed, also a name starting with a dot.\nObject names can contain a number but cannot start with a number.\nR is case sensitive, X and x are two different objects, as well as temp and temP.\n\n\nLets do some coding\nSimple calculations\n\n5\n\n[1] 5\n\n\n\n2+5\n\n[1] 7\n\n\n\nlog(5)\n\n[1] 1.609438\n\n\n\n\nStoring objects\nStore a number\n\nx <- 2\nx\n\n[1] 2\n\n\nTry it with =\n\nx=2\nx\n\n[1] 2\n\n\nSame results\nStore an object\n\nx <- \"Hello\"\nx\n\n[1] \"Hello\"\n\n\nStore a string of numbers\n\nx <- c(1:10)\nx\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\nCheck the string and subset some values based on criteria\n\nx>8\n\n [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE\n\n\n\nx < 5\n\n [1]  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE\n\n\n\nx[(x>8) | (x<5)]\n\n[1]  1  2  3  4  9 10\n\n\n\n\nVectors\nWrite a vector of weights\n\nweight <- c(55, 67, 99, 87, 62, 45, 32, 6, 22, 88)\n\nSubset the third value\n\nweight[3]\n\n[1] 99\n\n\nSubset the 4th to 6th value\n\nweight[4:6]\n\n[1] 87 62 45\n\n\nDefine another vector of weights\n\nheight <- c(123, 165, 187, 201, 152, 157, 134, 23, 91, 197)\n\nEstimate a BMI\n\nbmi <- weight/((height/100)^2)\nbmi\n\n [1]  36.35402  24.60973  28.31079  21.53412  26.83518  18.25632  17.82134\n [8] 113.42155  26.56684  22.67515\n\n\n\n\nDescriptive of the vector\n\nlength(height)\n\n[1] 10\n\n\n\nmean (weight)\n\n[1] 56.3\n\n\n\nvar(height)\n\n[1] 2951.333\n\n\n\n\nMatrices\nDefine a new vector\n\nobs <- 1:10\n\nJoin them into a matrix\n\nm <- cbind(obs, height, weight, bmi)\n\nDescribe the matrix\n\ntypeof(m)\n\n[1] \"double\"\n\n\n\nclass(m)\n\n[1] \"matrix\" \"array\" \n\n\n\nis.matrix(m)\n\n[1] TRUE\n\n\n\ndim(m)\n\n[1] 10  4\n\n\n\n\nQuick and dirty plots in base R\n\nxplot <- plot(height, weight, ylab=\"Weight\", xlab=\"Height\")\n\n\n\n\n\nxplot\n\nNULL\n\n\n\n\nDataframes\nConvert the earlier matrix into a df\n\ndf <- as.data.frame(m)\n\nCheck the column names\n\nnames(df)\n\n[1] \"obs\"    \"height\" \"weight\" \"bmi\"   \n\n\nSummarise the columns\n\nsummary(df)\n\n      obs            height          weight           bmi        \n Min.   : 1.00   Min.   : 23.0   Min.   : 6.00   Min.   : 17.82  \n 1st Qu.: 3.25   1st Qu.:125.8   1st Qu.:35.25   1st Qu.: 21.82  \n Median : 5.50   Median :154.5   Median :58.50   Median : 25.59  \n Mean   : 5.50   Mean   :143.0   Mean   :56.30   Mean   : 33.64  \n 3rd Qu.: 7.75   3rd Qu.:181.5   3rd Qu.:82.00   3rd Qu.: 27.94  \n Max.   :10.00   Max.   :201.0   Max.   :99.00   Max.   :113.42  \n\n\n\n\nSome other importannt grammar\n\nls() lists all the function objects in the environment\n\n\nls()\n\n\nrm() removes a particular function, rm(list=ls()) empties the environment\n\n\nrm(x)\n\n\n\n\nSpecial characters\n\nNA: Not Available (i.e. missing values)\nNaN: Not a Number (e.g. 0/0)\nInf: Infinity\n-Inf: Minus Infinity.\n\nFor instance 0 divided by 0 gives a NaN, but 1 divided by 0 gives Inf.\n\nThere are many ways to skin a cat in R\n\n\n\n\n\nFor instance\n\nmean(df$height) \n\n[1] 143\n\n\nOr\n\nwith(df, mean(height))\n\n[1] 143\n\n\nOr\n\nmean(height, data=df)\n\n[1] 143\n\n\nOr for a plot you could\n\nplot(df$height,df$weight)\n\n\n\n\nor\n\nwith(df, plot(height,weight)) \n\n\n\n\nor\n\nplot(weight~height, data=df)\n\n\n\n\nOf course not every thing will work\n\nplot(height, weight, data=df)\n\nWarning in plot.window(...): \"data\" is not a graphical parameter\n\n\nWarning in plot.xy(xy, type, ...): \"data\" is not a graphical parameter\n\n\nWarning in axis(side = side, at = at, labels = labels, ...): \"data\" is not a\ngraphical parameter\n\nWarning in axis(side = side, at = at, labels = labels, ...): \"data\" is not a\ngraphical parameter\n\n\nWarning in box(...): \"data\" is not a graphical parameter\n\n\nWarning in title(...): \"data\" is not a graphical parameter\n\n\n\n\n\n\n\n\nA word on the tidyverse\n\nThe tidyr and dplyr packages handle SQL-ytpe work: merging files, extracting subsets, etc.\n\n\n#install tidyerse\ninstall.packages(\"tidyverse\")\n\n#load dtidyverse\nlibrary(tidyverse)\n\n#wranggle data\nsub_df <- df %>% filter(bmi>20) %>% \n  mutate(BMI=bmi*bmi)#takes a sample of size 5000, extracts only the rows for which age > 18, and saves the result in newNCHS\n\nThe tidyverse framework is AMAZING and we will focus on utilising this framework for the remainder of this workshop.\n\n\n\n\n\n\nTip\n\n\n\n\nNobody remembers everything\nFirst thing to check is CRAN- look for documentation of package\ntype ? in console\nStackoverflow, Rstudio forum etc\nREMEMBER R IS ALL ABOUT COMMUNITY\n\n\n\n\n\nAcknowledgements\nMaterial for this lecture was borrowed and adopted from\n\nhttps://stephaniehicks.com/jhustatcomputing2022/\nhttps://rafalab.github.io/dsbook\nhttps://rmd4sci.njtierney.com\n\n\n\nAdditional Resources\n\n\n\n\n\n\nTip\n\n\n\n\nProgramming in R\n\n\nAn Introduction to R Complete introduction to base R\nR for Data Science Introduction to data analysis using R\nAdvanced R In-depth discussion of programming in R\n\n\nData viz in R\n\n\nData Visualization\nElegant Graphics for Data Analysis\n\n\nExtensions to R\n\n\nProgramming interactive R-apps using Shiny\nR markdown Integrate code and output into typeset documents and slide\nRStudio Cheat Sheets Cheatsheets for numerous packages."
  },
  {
    "objectID": "regression.html",
    "href": "regression.html",
    "title": "Progression to Regression: An Introduction to Regression in R",
    "section": "",
    "text": "Regression analysis is a powerful statistical tool that allows researchers to investigate relationships between variables, specifically the relationship between a dependent variable and one or more independent variables. In healthcare data, regression analysis is used for numerous purposes:\n\nPrediction and Forecasting: Regression analysis can help forecast future health trends based on historical data. For example, it can predict the prevalence of a disease based on risk factors.\nIdentifying Risk Factors: Regression analysis can be used to identify risk factors for diseases. For example, it can help determine whether smoking is a significant risk factor for lung cancer.\nCost-effectiveness Analysis: In health economics, regression analysis can help analyze the cost-effectiveness of different treatments or interventions.\nEvaluating Treatment Effects: Regression can be used to compare the effects of different treatments in a population, which can inform healthcare decision-making.\n\nHere are some important regression models used in healthcare data analysis:\n\nLinear Regression: Linear regression is used when the dependent variable is continuous. For example, it could be used to examine the relationship between age (independent variable) and blood pressure (dependent variable).\nLogistic Regression: Logistic regression is used when the dependent variable is binary, i.e., it has two possible outcomes. It is often used to identify risk factors for diseases. For example, it could be used to investigate the impact of various factors (like age, sex, BMI, smoking status) on the likelihood of developing heart disease (Yes/No).\nCox Regression: Cox regression, or proportional hazards regression, is a type of survival analysis used to investigate the effect of various factors on the time a specified event takes to happen. For example, it can be used to study the survival time of patients after being diagnosed with a certain disease.\nPoisson Regression: Poisson regression is used for count data. For instance, it can model the number of hospital admissions over a certain period.\nMultilevel Regression: Multilevel (or hierarchical) regression is used when data is grouped, such as patients within hospitals. This takes into account the potential correlation of patients within the same group.\nNonlinear Regression: Nonlinear regression can be used when the relationship between the independent and dependent variables is not linear.\n\nRemember, selecting the appropriate regression model depends largely on the type of data at hand and the specific research question. We will be introducing the approach to univariable and multivariable linear and logistic regression analysis in R.\nBefore we start lets get some important packages loaded\n\nrequired_packages <- c(\"tidyverse\", \"lubridate\", \"gtsummary\", \"broom\", \"performance\", \"see\", \"flextable\", \"stats\", \"car\")\nnot_installed <- required_packages[!(required_packages %in% installed.packages()[ , \"Package\"])]    \nif(length(not_installed)) install.packages(not_installed)                                           \nsuppressWarnings(lapply(required_packages, require, character.only = TRUE))\n\nLoading required package: tidyverse\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\nLoading required package: gtsummary\n\nLoading required package: broom\n\nLoading required package: performance\n\nLoading required package: see\n\nLoading required package: flextable\n\n\nAttaching package: 'flextable'\n\n\nThe following objects are masked from 'package:gtsummary':\n\n    as_flextable, continuous_summary\n\n\nThe following object is masked from 'package:purrr':\n\n    compose\n\n\nLoading required package: car\n\nLoading required package: carData\n\n\nAttaching package: 'car'\n\n\nThe following object is masked from 'package:dplyr':\n\n    recode\n\n\nThe following object is masked from 'package:purrr':\n\n    some\n\n\nLets call in the data:\n\nc19_df <- read.csv(\"https://raw.githubusercontent.com/MoH-Malaysia/covid19-public/main/epidemic/linelist/linelist_deaths.csv\")\n\n#create a sequence of numbers to represent time\nc19_df <- c19_df %>%\n  arrange(date) %>%\n  group_by(date) %>%\n  mutate(date_index = cur_group_id(),\n         age_cat=ifelse(age<20, \"Less than 20\",\n                        ifelse(age %in% 20:40, \"20-40\",\n                               ifelse(age %in% 40:60, \"40-60\",\n                                      ifelse(age %in% 60:80, \"60:80\", \">80\"))))) %>%\n  ungroup()\n\nJust to be consistent we what I said yesterday- before diving into the data always always skim the data first to get a quick feels\n\nc19_df %>% \n  skimr::skim()\n\n\nData summary\n\n\nName\nPiped data\n\n\nNumber of rows\n37152\n\n\nNumber of columns\n17\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n11\n\n\nnumeric\n6\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\ndate\n0\n1\n10\n10\n0\n1004\n0\n\n\ndate_announced\n0\n1\n10\n10\n0\n1000\n0\n\n\ndate_positive\n0\n1\n10\n10\n0\n999\n0\n\n\ndate_dose1\n0\n1\n0\n10\n22437\n298\n0\n\n\ndate_dose2\n0\n1\n0\n10\n28034\n267\n0\n\n\ndate_dose3\n0\n1\n0\n10\n35719\n161\n0\n\n\nbrand1\n0\n1\n0\n16\n22437\n8\n0\n\n\nbrand2\n0\n1\n0\n16\n28034\n7\n0\n\n\nbrand3\n0\n1\n0\n16\n35719\n6\n0\n\n\nstate\n0\n1\n5\n17\n0\n16\n0\n\n\nage_cat\n0\n1\n3\n12\n0\n5\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nage\n0\n1\n62.65\n16.59\n0\n51\n64\n75\n130\n▁▃▇▃▁\n\n\nmale\n0\n1\n0.58\n0.49\n0\n0\n1\n1\n1\n▆▁▁▁▇\n\n\nbid\n0\n1\n0.21\n0.41\n0\n0\n0\n0\n1\n▇▁▁▁▂\n\n\nmalaysian\n0\n1\n0.89\n0.31\n0\n1\n1\n1\n1\n▁▁▁▁▇\n\n\ncomorb\n0\n1\n0.79\n0.41\n0\n1\n1\n1\n1\n▂▁▁▁▇\n\n\ndate_index\n0\n1\n419.07\n122.14\n1\n362\n393\n444\n1004\n▁▇▆▁▁\n\n\n\n\n\n\nLinear regression\nThe R function lm() perform linear regression, assessing the relationship between numeric response and explanatory variables that are assumed to have a linear relationship.\nProvide the equation as a formula, with the response and explanatory column names separated by a tilde ~. Also, specify the dataset to data =. Define the model results as an R object, to use later.\n\nUnivariate linear regression\n\nlm_results <- lm(age ~ malaysian, data = c19_df)\n\nYou can then run summary() on the model results to see the coefficients (Estimates), P-value, residuals, and other measures.\n\nsummary(lm_results)\n\n\nCall:\nlm(formula = age ~ malaysian, data = c19_df)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-64.26 -10.26   0.74  11.74  80.53 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  49.4727     0.2509  197.14   <2e-16 ***\nmalaysian    14.7875     0.2658   55.63   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 15.94 on 37150 degrees of freedom\nMultiple R-squared:  0.07691,   Adjusted R-squared:  0.07689 \nF-statistic:  3095 on 1 and 37150 DF,  p-value: < 2.2e-16\n\n\nAlternatively you can use the tidy() function from the broom package to pull the results in to a table. What the results tell us is that Malaysians (change from 0 to 1) the age of COVID-19 death increases by 14.8 years and this is statistically significant (p<0.01).\n\ntidy(lm_results)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic p.value\n  <chr>          <dbl>     <dbl>     <dbl>   <dbl>\n1 (Intercept)     49.5     0.251     197.        0\n2 malaysian       14.8     0.266      55.6       0\n\n\nYou can then also use this regression to add it to a ggplot, to do this we first pull the points for the observed data and the fitted line in to one data frame using the augment() function from broom.\n\n## pull the regression points and observed data in to one dataset\npoints <- augment(lm_results)\n\n## plot the data using age as the x-axis \nggplot(points, aes(x = malaysian)) + \n  ## add points for height \n  geom_point(aes(y = age)) + \n  ## add your regression line \n  geom_line(aes(y = .fitted), colour = \"red\")\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWhen using a categorical variable as the predictor as we did above the plots can appear somewhat difficult to understand. We can try using a continuous on continuous method and implement it more simpler directly in ggplot and it should look like:\n\n## add your data to a plot \n ggplot(c19_df, aes(x = date_index, y = age)) + \n  ## show points\n  geom_point() + \n  ## add a linear regression \n  geom_smooth(method = \"lm\", se = FALSE)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nMultivariable linear regression\nThere is almost no difference when carrying out multivariable linear regression, instead we just add on the expression + to add more variables to the equation.\n\nlm_results <- lm(age ~ malaysian + bid + male + state + comorb, \n                 data = c19_df)\n\nCheck the output\n\ntidy(lm_results)\n\n# A tibble: 20 × 5\n   term                   estimate std.error statistic  p.value\n   <chr>                     <dbl>     <dbl>     <dbl>    <dbl>\n 1 (Intercept)             47.6        0.380  125.     0       \n 2 malaysian               12.9        0.284   45.3    0       \n 3 bid                     -1.25       0.209   -5.96   2.57e- 9\n 4 male                    -1.41       0.165   -8.58   9.74e-18\n 5 stateKedah               1.48       0.376    3.95   7.86e- 5\n 6 stateKelantan            4.94       0.474   10.4    2.18e-25\n 7 stateMelaka              0.763      0.504    1.51   1.30e- 1\n 8 stateNegeri Sembilan     3.19       0.459    6.95   3.80e-12\n 9 statePahang              1.92       0.537    3.57   3.56e- 4\n10 statePerak               5.27       0.407   12.9    3.65e-38\n11 statePerlis              6.10       1.13     5.38   7.61e- 8\n12 statePulau Pinang        5.42       0.412   13.2    1.88e-39\n13 stateSabah               6.45       0.362   17.8    1.26e-70\n14 stateSarawak             6.06       0.436   13.9    6.18e-44\n15 stateSelangor            0.0115     0.274    0.0422 9.66e- 1\n16 stateTerengganu          3.05       0.569    5.36   8.55e- 8\n17 stateW.P. Kuala Lumpur   2.96       0.373    7.93   2.21e-15\n18 stateW.P. Labuan         0.245      1.26     0.194  8.46e- 1\n19 stateW.P. Putrajaya      2.96       2.92     1.01   3.10e- 1\n20 comorb                   3.00       0.210   14.3    4.79e-46\n\n\nPretty simple right!\n\n\nUnivariate logistic regression\nThe function glm() from the stats package (part of base R) is used to fit Generalized Linear Models (GLM). glm() can be used for univariate and multivariable logistic regression (e.g. to get Odds Ratios). Here are the core parts:\n\nformula = The model is provided to glm() as an equation, with the outcome on the left and explanatory variables on the right of a tilde ~.\nfamily = This determines the type of model to run. For logistic regression, use family = \"binomial\", for poisson use family = \"poisson\". Other examples are in the table below.\ndata = Specify your data frame\n\nIf necessary, you can also specify the link function via the syntax family = familytype(link = \"linkfunction\")). You can read more in the documentation about other families and optional arguments such as weights = and subset = (?glm).\n\n\n\nFamily\nDefault link function\n\n\n\n\n\"binomial\"\n(link = \"logit\")\n\n\n\"gaussian\"\n(link = \"identity\")\n\n\n\"Gamma\"\n(link = \"inverse\")\n\n\n\"inverse.gaussian\"\n(link = \"1/mu^2\")\n\n\n\"poisson\"\n(link = \"log\")\n\n\n\"quasi\"\n(link = \"identity\", variance = \"constant\")\n\n\n\"quasibinomial\"\n(link = \"logit\")\n\n\n\"quasipoisson\"\n(link = \"log\")\n\n\n\nWhen running glm() it is most common to save the results as a named R object. Then you can print the results to your console using summary() as shown below, or perform other operations on the results (e.g. exponentiate). If you need to run a negative binomial regression you can use the MASS package; the glm.nb() uses the same syntax as glm(). For a walk-through of different regressions, see the UCLA stats page. So lets try to run a logistic regression model first:\n\nmodel <- glm(malaysian ~ age_cat, family = \"binomial\", data = c19_df)\nsummary(model)\n\n\nCall:\nglm(formula = malaysian ~ age_cat, family = \"binomial\", data = c19_df)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.7224   0.2231   0.2747   0.6605   0.7777  \n\nCoefficients:\n                    Estimate Std. Error z value Pr(>|z|)    \n(Intercept)          3.68075    0.08588  42.859  < 2e-16 ***\nage_cat20-40        -2.63967    0.09382 -28.135  < 2e-16 ***\nage_cat40-60        -2.26931    0.08895 -25.512  < 2e-16 ***\nage_cat60:80        -0.42226    0.09566  -4.414 1.01e-05 ***\nage_catLess than 20 -2.19915    0.18614 -11.814  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 25526  on 37151  degrees of freedom\nResidual deviance: 22412  on 37147  degrees of freedom\nAIC: 22422\n\nNumber of Fisher Scoring iterations: 6\n\n\nCan you spot a potential issue in the summary above?\n\nc19_df %>% \n  mutate(age_cat = fct_relevel(age_cat, \"Less than 20\", after = 0)) %>% \n  glm(formula = malaysian ~ age_cat, family = \"binomial\") %>% \n  summary()\n\n\nCall:\nglm(formula = malaysian ~ age_cat, family = \"binomial\", data = .)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.7224   0.2231   0.2747   0.6605   0.7777  \n\nCoefficients:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept)   1.48160    0.16514   8.972  < 2e-16 ***\nage_cat>80    2.19915    0.18614  11.814  < 2e-16 ***\nage_cat20-40 -0.44052    0.16941  -2.600  0.00931 ** \nage_cat40-60 -0.07017    0.16676  -0.421  0.67394    \nage_cat60:80  1.77689    0.17043  10.426  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 25526  on 37151  degrees of freedom\nResidual deviance: 22412  on 37147  degrees of freedom\nAIC: 22422\n\nNumber of Fisher Scoring iterations: 6\n\n\nLets clean that up so we have a nice exponentiated and round up the hyper precise output:\n\nmodel <- glm(malaysian ~ age_cat, family = \"binomial\", data = c19_df) %>% \n  tidy(exponentiate = TRUE, conf.int = TRUE) %>%        # exponentiate and produce CIs\n  mutate(across(where(is.numeric), round, digits = 2))  # round all numeric columns\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `across(where(is.numeric), round, digits = 2)`.\nCaused by warning:\n! The `...` argument of `across()` is deprecated as of dplyr 1.1.0.\nSupply arguments directly to `.fns` through an anonymous function instead.\n\n  # Previously\n  across(a:b, mean, na.rm = TRUE)\n\n  # Now\n  across(a:b, \\(x) mean(x, na.rm = TRUE))\n\nmodel\n\n# A tibble: 5 × 7\n  term                estimate std.error statistic p.value conf.low conf.high\n  <chr>                  <dbl>     <dbl>     <dbl>   <dbl>    <dbl>     <dbl>\n1 (Intercept)            39.7       0.09     42.9        0    33.7      47.2 \n2 age_cat20-40            0.07      0.09    -28.1        0     0.06      0.09\n3 age_cat40-60            0.1       0.09    -25.5        0     0.09      0.12\n4 age_cat60:80            0.66      0.1      -4.41       0     0.54      0.79\n5 age_catLess than 20     0.11      0.19    -11.8        0     0.08      0.16\n\n\n\n\nMultivariable logistic regression\nThe expressions utilised are exactly the same as in the multivariable linear regression model\n\nlog_reg <- glm(malaysian ~ age_cat + bid + comorb + male + state, \n               family = \"binomial\", data = c19_df)\n\ntidy(log_reg, exponentiate = TRUE, conf.int = TRUE)\n\n# A tibble: 23 × 7\n   term                estimate std.error statistic   p.value conf.low conf.high\n   <chr>                  <dbl>     <dbl>     <dbl>     <dbl>    <dbl>     <dbl>\n 1 (Intercept)          38.4       0.112      32.5  2.49e-232  30.9      48.0   \n 2 age_cat20-40          0.0709    0.101     -26.3  3.00e-152   0.0580    0.0861\n 3 age_cat40-60          0.106     0.0943    -23.8  9.11e-125   0.0881    0.128 \n 4 age_cat60:80          0.535     0.100      -6.26 3.75e- 10   0.438     0.648 \n 5 age_catLess than 20   0.142     0.205      -9.51 1.94e- 21   0.0955    0.214 \n 6 bid                   0.282     0.0398    -31.8  2.41e-221   0.261     0.305 \n 7 comorb                3.45      0.0396     31.3  1.59e-215   3.20      3.73  \n 8 male                  1.09      0.0394      2.29 2.20e-  2   1.01      1.18  \n 9 stateKedah            3.37      0.139       8.76 1.88e- 18   2.58      4.45  \n10 stateKelantan         2.75      0.194       5.22 1.76e-  7   1.91      4.09  \n# ℹ 13 more rows\n\n\nIf you want to include two variables and an interaction between them you can separate them with an asterisk * instead of a +. Separate them with a colon : if you are only specifying the interaction. For example:\n\nlog_intrx_reg <- glm(malaysian ~ age_cat*bid + comorb + male + state, \n               family = \"binomial\", data = c19_df)\n\ntidy(log_reg, exponentiate = TRUE, conf.int = TRUE)\n\n# A tibble: 23 × 7\n   term                estimate std.error statistic   p.value conf.low conf.high\n   <chr>                  <dbl>     <dbl>     <dbl>     <dbl>    <dbl>     <dbl>\n 1 (Intercept)          38.4       0.112      32.5  2.49e-232  30.9      48.0   \n 2 age_cat20-40          0.0709    0.101     -26.3  3.00e-152   0.0580    0.0861\n 3 age_cat40-60          0.106     0.0943    -23.8  9.11e-125   0.0881    0.128 \n 4 age_cat60:80          0.535     0.100      -6.26 3.75e- 10   0.438     0.648 \n 5 age_catLess than 20   0.142     0.205      -9.51 1.94e- 21   0.0955    0.214 \n 6 bid                   0.282     0.0398    -31.8  2.41e-221   0.261     0.305 \n 7 comorb                3.45      0.0396     31.3  1.59e-215   3.20      3.73  \n 8 male                  1.09      0.0394      2.29 2.20e-  2   1.01      1.18  \n 9 stateKedah            3.37      0.139       8.76 1.88e- 18   2.58      4.45  \n10 stateKelantan         2.75      0.194       5.22 1.76e-  7   1.91      4.09  \n# ℹ 13 more rows\n\n\n\n\n\nModel building\nYou can build your model step-by-step, saving various models that include certain explanatory variables. You can compare these models with likelihood-ratio tests using lrtest() from the package lmtest, as below:\n\nmodel1 <- glm(malaysian ~ age_cat, family = \"binomial\", data = c19_df)\nmodel2 <- glm(malaysian ~ age_cat + bid, family = \"binomial\", data = c19_df)\n\nlmtest::lrtest(model1, model2)\n\nLikelihood ratio test\n\nModel 1: malaysian ~ age_cat\nModel 2: malaysian ~ age_cat + bid\n  #Df LogLik Df  Chisq Pr(>Chisq)    \n1   5 -11206                         \n2   6 -10375  1 1661.8  < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nIf you prefer to instead leverage the computation available within you processor we can instead take the model object and apply the step() function from the stats package. Specify which variable selection direction you want use when building the model.\n\n## choose a model using forward selection based on AIC\n## you can also do \"backward\" or \"both\" by adjusting the direction\nfinal_log_reg <- log_reg %>%\n  step(direction = \"both\", trace = FALSE)\n\nCheck the best fitting models based on both a backward and forward method\n\nlog_tab_base <- final_log_reg %>% \n  broom::tidy(exponentiate = TRUE, conf.int = TRUE) %>%  ## get a tidy dataframe of estimates \n  mutate(across(where(is.numeric), round, digits = 2))          ## round \n\n#check\nlog_tab_base\n\n# A tibble: 23 × 7\n   term                estimate std.error statistic p.value conf.low conf.high\n   <chr>                  <dbl>     <dbl>     <dbl>   <dbl>    <dbl>     <dbl>\n 1 (Intercept)            38.4       0.11     32.5     0       31.0      48.0 \n 2 age_cat20-40            0.07      0.1     -26.3     0        0.06      0.09\n 3 age_cat40-60            0.11      0.09    -23.8     0        0.09      0.13\n 4 age_cat60:80            0.53      0.1      -6.26    0        0.44      0.65\n 5 age_catLess than 20     0.14      0.21     -9.51    0        0.1       0.21\n 6 bid                     0.28      0.04    -31.8     0        0.26      0.31\n 7 comorb                  3.45      0.04     31.3     0        3.2       3.73\n 8 male                    1.09      0.04      2.29    0.02     1.01      1.18\n 9 stateKedah              3.37      0.14      8.76    0        2.58      4.45\n10 stateKelantan           2.75      0.19      5.22    0        1.91      4.09\n# ℹ 13 more rows\n\n\n\n\ngtsummary() and regression\nMy favourite package again. The gtsummary package provides the tbl_regression() function, which will take the outputs from a regression (glm() in this case) and produce an nice summary table.\n\n## show results table of final regression \nmv_tab <- tbl_regression(final_log_reg, exponentiate = TRUE)\n\n#check\nmv_tab\n\n\n\n\n\n  \n  \n    \n      Characteristic\n      OR1\n      95% CI1\n      p-value\n    \n  \n  \n    age_cat\n\n\n\n        >80\n—\n—\n\n        20-40\n0.07\n0.06, 0.09\n<0.001\n        40-60\n0.11\n0.09, 0.13\n<0.001\n        60:80\n0.53\n0.44, 0.65\n<0.001\n        Less than 20\n0.14\n0.10, 0.21\n<0.001\n    bid\n0.28\n0.26, 0.31\n<0.001\n    comorb\n3.45\n3.20, 3.73\n<0.001\n    male\n1.09\n1.01, 1.18\n0.022\n    state\n\n\n\n        Johor\n—\n—\n\n        Kedah\n3.37\n2.58, 4.45\n<0.001\n        Kelantan\n2.75\n1.91, 4.09\n<0.001\n        Melaka\n2.22\n1.61, 3.14\n<0.001\n        Negeri Sembilan\n1.30\n1.00, 1.71\n0.055\n        Pahang\n1.86\n1.33, 2.65\n<0.001\n        Perak\n2.85\n2.11, 3.92\n<0.001\n        Perlis\n2.75\n1.10, 9.25\n0.057\n        Pulau Pinang\n0.81\n0.66, 1.00\n0.044\n        Sabah\n0.26\n0.23, 0.31\n<0.001\n        Sarawak\n4.49\n2.96, 7.15\n<0.001\n        Selangor\n0.47\n0.41, 0.54\n<0.001\n        Terengganu\n3.16\n1.96, 5.44\n<0.001\n        W.P. Kuala Lumpur\n0.40\n0.34, 0.47\n<0.001\n        W.P. Labuan\n0.44\n0.28, 0.72\n<0.001\n        W.P. Putrajaya\n34,834\n340, 10,238,707,683,122,566\n>0.9\n  \n  \n  \n    \n      1 OR = Odds Ratio, CI = Confidence Interval\n    \n  \n\n\n\n\nIts so good! But it doesn’t end there. tbl_uvregression() from the gtsummary package produces a table of univariate regression results. We select only the necessary columns from the linelist (explanatory variables and the outcome variable) and pipe them into tbl_uvregression(). We are going to run univariate regression on each of the columns we defined as explanatory_vars in the data\nWithin the function itself, we provide the method = as glm (no quotes), the y = outcome column (outcome), specify to method.args = that we want to run logistic regression via family = binomial, and we tell it to exponentiate the results.\nThe output is HTML and contains the counts\n\n## define variables of interest \nexplanatory_vars <- c(\"bid\", \"male\", \"comorb\", \"age_cat\", \"state\")#lets leave state ut to increase the computation\n\n#cteate a data subset and run the regression\nuniv_tab <- c19_df %>% \n  dplyr::select(explanatory_vars, malaysian) %>% ## select variables of interest\n\n  tbl_uvregression(                         ## produce univariate table\n    method = glm,                           ## define regression want to run (generalised linear model)\n    y = malaysian,                            ## define outcome variable\n    method.args = list(family = binomial),  ## define what type of glm want to run (logistic)\n    exponentiate = TRUE                     ## exponentiate to produce odds ratios (rather than log odds)\n  )\n\n## view univariate results table \nuniv_tab\n\n\n\n\n\n  \n  \n    \n      Characteristic\n      N\n      OR1\n      95% CI1\n      p-value\n    \n  \n  \n    bid\n37,152\n0.20\n0.19, 0.22\n<0.001\n    male\n37,152\n0.93\n0.87, 0.99\n0.029\n    comorb\n37,152\n5.61\n5.24, 6.00\n<0.001\n    age_cat\n37,152\n\n\n\n        >80\n\n—\n—\n\n        20-40\n\n0.07\n0.06, 0.09\n<0.001\n        40-60\n\n0.10\n0.09, 0.12\n<0.001\n        60:80\n\n0.66\n0.54, 0.79\n<0.001\n        Less than 20\n\n0.11\n0.08, 0.16\n<0.001\n    state\n37,152\n\n\n\n        Johor\n\n—\n—\n\n        Kedah\n\n3.21\n2.49, 4.20\n<0.001\n        Kelantan\n\n3.65\n2.57, 5.37\n<0.001\n        Melaka\n\n2.22\n1.63, 3.10\n<0.001\n        Negeri Sembilan\n\n1.51\n1.19, 1.95\n0.001\n        Pahang\n\n1.98\n1.45, 2.79\n<0.001\n        Perak\n\n3.40\n2.55, 4.61\n<0.001\n        Perlis\n\n4.08\n1.72, 13.3\n0.006\n        Pulau Pinang\n\n0.85\n0.71, 1.03\n0.094\n        Sabah\n\n0.34\n0.29, 0.38\n<0.001\n        Sarawak\n\n6.45\n4.32, 10.1\n<0.001\n        Selangor\n\n0.41\n0.36, 0.46\n<0.001\n        Terengganu\n\n4.37\n2.76, 7.43\n<0.001\n        W.P. Kuala Lumpur\n\n0.33\n0.29, 0.38\n<0.001\n        W.P. Labuan\n\n0.39\n0.26, 0.61\n<0.001\n        W.P. Putrajaya\n\n65,203\n434, 166,983,382,533,055,616\n>0.9\n  \n  \n  \n    \n      1 OR = Odds Ratio, CI = Confidence Interval\n    \n  \n\n\n\n\nNow for some magic\n\n## combine with univariate results \nmv_merge <- tbl_merge(\n  tbls = list(univ_tab, mv_tab),                          # combine\n  tab_spanner = c(\"**Univariate**\", \"**Multivariable**\")) # set header names\n\n#check\nmv_merge\n\n\n\n\n\n  \n  \n    \n      Characteristic\n      \n        Univariate\n      \n      \n        Multivariable\n      \n    \n    \n      N\n      OR1\n      95% CI1\n      p-value\n      OR1\n      95% CI1\n      p-value\n    \n  \n  \n    bid\n37,152\n0.20\n0.19, 0.22\n<0.001\n0.28\n0.26, 0.31\n<0.001\n    male\n37,152\n0.93\n0.87, 0.99\n0.029\n1.09\n1.01, 1.18\n0.022\n    comorb\n37,152\n5.61\n5.24, 6.00\n<0.001\n3.45\n3.20, 3.73\n<0.001\n    age_cat\n37,152\n\n\n\n\n\n\n        >80\n\n—\n—\n\n—\n—\n\n        20-40\n\n0.07\n0.06, 0.09\n<0.001\n0.07\n0.06, 0.09\n<0.001\n        40-60\n\n0.10\n0.09, 0.12\n<0.001\n0.11\n0.09, 0.13\n<0.001\n        60:80\n\n0.66\n0.54, 0.79\n<0.001\n0.53\n0.44, 0.65\n<0.001\n        Less than 20\n\n0.11\n0.08, 0.16\n<0.001\n0.14\n0.10, 0.21\n<0.001\n    state\n37,152\n\n\n\n\n\n\n        Johor\n\n—\n—\n\n—\n—\n\n        Kedah\n\n3.21\n2.49, 4.20\n<0.001\n3.37\n2.58, 4.45\n<0.001\n        Kelantan\n\n3.65\n2.57, 5.37\n<0.001\n2.75\n1.91, 4.09\n<0.001\n        Melaka\n\n2.22\n1.63, 3.10\n<0.001\n2.22\n1.61, 3.14\n<0.001\n        Negeri Sembilan\n\n1.51\n1.19, 1.95\n0.001\n1.30\n1.00, 1.71\n0.055\n        Pahang\n\n1.98\n1.45, 2.79\n<0.001\n1.86\n1.33, 2.65\n<0.001\n        Perak\n\n3.40\n2.55, 4.61\n<0.001\n2.85\n2.11, 3.92\n<0.001\n        Perlis\n\n4.08\n1.72, 13.3\n0.006\n2.75\n1.10, 9.25\n0.057\n        Pulau Pinang\n\n0.85\n0.71, 1.03\n0.094\n0.81\n0.66, 1.00\n0.044\n        Sabah\n\n0.34\n0.29, 0.38\n<0.001\n0.26\n0.23, 0.31\n<0.001\n        Sarawak\n\n6.45\n4.32, 10.1\n<0.001\n4.49\n2.96, 7.15\n<0.001\n        Selangor\n\n0.41\n0.36, 0.46\n<0.001\n0.47\n0.41, 0.54\n<0.001\n        Terengganu\n\n4.37\n2.76, 7.43\n<0.001\n3.16\n1.96, 5.44\n<0.001\n        W.P. Kuala Lumpur\n\n0.33\n0.29, 0.38\n<0.001\n0.40\n0.34, 0.47\n<0.001\n        W.P. Labuan\n\n0.39\n0.26, 0.61\n<0.001\n0.44\n0.28, 0.72\n<0.001\n        W.P. Putrajaya\n\n65,203\n434, 166,983,382,533,055,616\n>0.9\n34,834\n340, 10,238,707,683,122,566\n>0.9\n  \n  \n  \n    \n      1 OR = Odds Ratio, CI = Confidence Interval\n    \n  \n\n\n\n\nOne final piece of magic! We can export our publication ready regression table into a document. Lovely!\n\nmv_merge %>%\n  as_flex_table() %>%\n  flextable::save_as_docx(path = \"regression.docx\")\n\n\n\n\nModel evaluation in r using the performance() and car()\nLets just run through quickly how we can evaluate linear and logistics models in R.\n\nLinear model evaluation\nLinearity and Homoscedasticity: These can be checked using a residuals vs fitted values plot.\nFor linearity, we expect to see no pattern or curve in the points, while for homoscedasticity, we expect the spread of residuals to be approximately constant across all levels of the independent variables.\n\ncheck_model(lm_results)\n\nNormality of residuals: This can be checked using a QQ plot.\nIf the residuals are normally distributed, the points in the QQ plot will generally follow the straight line.\n\ncheck_normality(model)\n\nIndependence of residuals (No autocorrelation): This can be checked using the Durbin-Watson test.\nIf the test statistic is approximately 2, it indicates no autocorrelation.\n\ncheck_autocorrelation(model)\n\nNo multicollinearity: This can be checked using Variance Inflation Factor (VIF).\nA VIF value greater than 5 (some suggest 10) might indicate problematic multicollinearity.\n\ncheck_collinearity(model)\n\n\n\nLogistic model evaluation\nBinary Outcome: Logistic regression requires the dependent variable to be binary or ordinal in ordinal logistic regression.\nObservation Independence: Observations should be independent of each other. This is more of a study design issue than something you would check with a statistical test.\nNo Multicollinearity: Just like in linear regression, the independent variables should not be highly correlated with each other.\nJust like in linear regression, a rule of thumb is that if the VIF is greater than 5 (or sometimes 10), then the multicollinearity is high.\n\n# Checking for Multicollinearity:\ncheck_collinearity(mv_model)\n\nLinearity of Log Odds: While logistic regression does not assume linearity of the relationship between the independent variables and the dependent variable, it does assume linearity of independent variables and the log odds.\nChecking for Linearity of Log Odds:\nLogistic regression assumes that the log odds of the outcome is a linear combination of the independent variables. This is a complex assumption to check, but one approach is to look for significant interactions between your predictors and the log odds.\nFirst, fit a model that allows for the possibility of a non-linear relationship:\n\nlogit_model_2 <- glm(outcome ~ predictor + I(predictor^2), family=binomial, data=df)\n\nThen compare this model with your original model:\n\nanova(logit_model, logit_model_2, test=\"Chisq\")\n\nIf the model with the quadratic term is significantly better than the model without (i.e., p < 0.05), this could be a sign that the assumption of linearity of the log odds has been violated.\n\n\n\nAcknowledgements\nMaterial for this lecture was borrowed and adopted from\n\nThe Epidemiologist R Handbook\nhttps://rafalab.github.io/dsbook"
  },
  {
    "objectID": "regression_solutions.html",
    "href": "regression_solutions.html",
    "title": "Practical Statistics 4: Progression to Regression: An Introduction Regression",
    "section": "",
    "text": "Task 1: Univariate Linear Regression\nQuestion: Perform a univariate linear regression to predict “age” using the “male” variable.\nSteps:\n\nInstall and load the required packages: tidyverse and broom.\nFilter the dataset to remove missing values in the “age” and “male” columns.\nFit a univariate linear regression model using the lm() function.\nSummarise the model using tidy() from the broom package.\n\nSolution:\n\n# Step 1\n#install.packages(c(\"tidyverse\", \"broom\"))\nlibrary(tidyverse)\nlibrary(broom)\n\n# Step 2\nc19_df <- c19_df %>% filter(!is.na(age), !is.na(male))\n\n# Step 3\nmodel <- lm(age ~ male, data = c19_df)\n\n# Step 4\ntidy(model)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)    63.6      0.132    482.   0       \n2 male           -1.59     0.174     -9.14 6.51e-20\n\n\n\n\nTask 2: Multivariate Linear Regression\nQuestion: Perform a multivariate linear regression to predict “age” using the “male” and “malaysian” variables.\nSteps:\n\nFilter the dataset to remove missing values in the relevant columns.\nFit a multivariate linear regression model using the lm() function.\nSummarise the model using gtsummary().\nSave the output as a document\n\nSolution:\n\n# Step 1\nc19_df <- c19_df %>% filter(!is.na(age), !is.na(male), !is.na(malaysian))\n\n# Step 2\nmodel <- lm(age ~ male + malaysian, data = c19_df)\n\n# Step 3\nmodel %>% \n  tbl_regression() %>%\n  as_flex_table() %>%\n  flextable::save_as_docx(path = \"regression.docx\")\n\n\n\nTask 3: Univariate Logistic Regression\nQuestion: Perform a univariate logistic regression to predict “male” (binarize to 0 and 1) using the “age” variable.\nSteps:\n\nFilter the dataset to remove missing values in the relevant columns.\nFit a univariate logistic regression model using the glm() function, specifying the family as “binomial”.\nSummarise the model using tidy().\n\nSolution:\n\n# Step 1\nc19_df <- c19_df %>% filter(!is.na(age), !is.na(male))\n\n# Step 2\nmodel <- glm(male ~ age, data = c19_df, family = \"binomial\")\n\n# Step 3\ntidy(model)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)  0.667    0.0414       16.1  1.74e-58\n2 age         -0.00581  0.000637     -9.12 7.45e-20\n\n\n\n\nTask 4: Multivariate Logistic Regression\nQuestion: Perform a multivariate logistic regression to predict “male” using the “age” and “malaysian” variables.\nSteps:\n\nFilter the dataset to remove missing values in the relevant columns.\nFit a multivariate logistic regression model using the glm() function, specifying the family as “binomial”.\nSummarise the model using gtsummary().\nSave the output as a document\n\nSolution:\n\n# Step 1\nc19_df <- c19_df %>% filter(!is.na(age), !is.na(male), !is.na(malaysian))\n\n# Step 2\nmodel <- glm(male ~ age + malaysian, data = c19_df, family = \"binomial\")\n\n# Step 3\nmodel %>%\n  tbl_regression(exponentiate = TRUE) %>%\n  as_flex_table() %>%\n  flextable::save_as_docx(path = \"regression.docx\")\n\n\n\nTask 5: Model Evaluation\nQuestion: Evaluate the logistic regression model from Task 4 using AUC-ROC.\nSteps:\n\nInstall and load the pROC package (Note: Upon up the documentation to figure out the nuts and bolts.)\nUse the predict() function to get the predicted probabilities from the logistic regression model.\nUse the roc() function to compute the AUC-ROC.\n\nSolution:\n\n# Step 1\n#install.packages(\"pROC\")\nlibrary(pROC)\n\nType 'citation(\"pROC\")' for a citation.\n\n\n\nAttaching package: 'pROC'\n\n\nThe following objects are masked from 'package:stats':\n\n    cov, smooth, var\n\n# Step 2\nprobabilities <- predict(model, type = \"response\")\n\n# Step 3\nroc_obj <- roc(c19_df$male, probabilities)\n\nSetting levels: control = 0, case = 1\n\n\nSetting direction: controls < cases\n\n# Display AUC\nauc(roc_obj)\n\nArea under the curve: 0.5288"
  },
  {
    "objectID": "regression_tutorial.html",
    "href": "regression_tutorial.html",
    "title": "Practical Statistics 4: Progression to Regression: An Introduction Regression",
    "section": "",
    "text": "Task 2: Multivariate Linear Regression\nQuestion: Perform a multivariate linear regression to predict “age” using the “male” and “malaysian” variables.\nSteps:\n\nFilter the dataset to remove missing values in the relevant columns.\nFit a multivariate linear regression model using the lm() function.\nSummarise the model using gtsummary().\nSave the output as a document\n\n\n\nTask 3: Univariate Logistic Regression\nQuestion: Perform a univariate logistic regression to predict “male” (binarize to 0 and 1) using the “age” variable.\nSteps:\n\nFilter the dataset to remove missing values in the relevant columns.\nFit a univariate logistic regression model using the glm() function, specifying the family as “binomial”.\nSummarise the model using tidy().\n\n\n\nTask 4: Multivariate Logistic Regression\nQuestion: Perform a multivariate logistic regression to predict “male” using the “age” and “malaysian” variables.\nSteps:\n\nFilter the dataset to remove missing values in the relevant columns.\nFit a multivariate logistic regression model using the glm() function, specifying the family as “binomial”.\nSummarise the model using gtsummary().\nSave the output as a document\n\n\n\nTask 5: Model Evaluation\nQuestion: Evaluate the logistic regression model from Task 4 using AUC-ROC.\nSteps:\n\nInstall and load the pROC package (Note: Upon up the documentation to figure out the nuts and bolts.)\nUse the predict() function to get the predicted probabilities from the logistic regression model.\nUse the roc() function to compute the AUC-ROC."
  }
]